{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stable data\n",
    "x_stable_1  = np.genfromtxt(\"input_stable_1000.csv\", delimiter=',')\n",
    "y_stable_1  = np.genfromtxt(\"output_stable_1000.csv\", delimiter=',')\n",
    "\n",
    "x_stable_2  = np.genfromtxt(\"input_stable_2000.csv\", delimiter=',')\n",
    "y_stable_2  = np.genfromtxt(\"output_stable_2000.csv\", delimiter=',')\n",
    "\n",
    "# unstable data\n",
    "x_unstable_1  = np.genfromtxt(\"input_unstable_100.csv\", delimiter=',')\n",
    "y_unstable_1  = np.genfromtxt(\"output_unstable_100.csv\", delimiter=',')\n",
    "\n",
    "x_unstable_2  = np.genfromtxt(\"input_unstable_120.csv\", delimiter=',')\n",
    "y_unstable_2  = np.genfromtxt(\"output_unstable_120.csv\", delimiter=',')\n",
    "\n",
    "x_unstable_3  = np.genfromtxt(\"input_unstable_150.csv\", delimiter=',')\n",
    "y_unstable_3  = np.genfromtxt(\"output_unstable_150.csv\", delimiter=',')\n",
    "\n",
    "x_unstable_4  = np.genfromtxt(\"input_unstable_180.csv\", delimiter=',')\n",
    "y_unstable_4  = np.genfromtxt(\"output_unstable_180.csv\", delimiter=',')\n",
    "\n",
    "x_unstable_5  = np.genfromtxt(\"input_unstable_200.csv\", delimiter=',')\n",
    "y_unstable_5  = np.genfromtxt(\"output_unstable_200.csv\", delimiter=',')\n",
    "\n",
    "x_unstable_6  = np.genfromtxt(\"input_unstable_250.csv\", delimiter=',')\n",
    "y_unstable_6  = np.genfromtxt(\"output_unstable_250.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 27), (3000, 3))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From training data by concatenating data\n",
    "\n",
    "# x_train = np.concatenate((x_stable_1, x_stable_2, x_unstable_1, x_unstable_2, x_unstable_3, x_unstable_4, x_unstable_5, x_unstable_6), axis=0)\n",
    "# y_train = np.concatenate((y_stable_1, y_stable_2, y_unstable_1, y_unstable_2, y_unstable_3, y_unstable_4, y_unstable_5, y_unstable_6), axis=0)\n",
    "\n",
    "x_train = np.concatenate((x_stable_2, x_unstable_1, x_unstable_2, x_unstable_3, x_unstable_4, x_unstable_5, x_unstable_6), axis=0)\n",
    "y_train = np.concatenate((y_stable_2, y_unstable_1, y_unstable_2, y_unstable_3, y_unstable_4, y_unstable_5, y_unstable_6), axis=0)\n",
    "\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0,\n",
       " 0.045001259078598366,\n",
       " -0.07623773784599308,\n",
       " -4.0,\n",
       " 6.0,\n",
       " 0.03705011925890922)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abnormal data transformation\n",
    "y_train[:,0][y_train[:,0] >  4]   =  4      # rocof_max (has been transformed to absolute value, Hz/s)\n",
    "y_train[:,1][y_train[:,1] < -4]   = -4      # fnadir (Hz)\n",
    "y_train[:,1][y_train[:,1] >  4]   =  4      # fnadir (Hz)\n",
    "y_train[:,2][y_train[:,2] > 3.14] =  6      # maximum angle difference\n",
    "\n",
    "# check transformation results\n",
    "max(y_train[:,0]), min(y_train[:,0]), max(y_train[:,1]), min(y_train[:,1]), max(y_train[:,2]), min(y_train[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch tensor for training\n",
    "\n",
    "x_train = x_train[:, 11:] # remove pg\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 16\n",
    "hidden_dim = 64\n",
    "output_dim = 3\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "model = NeuralNetwork(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "dataset    = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3000], Loss: 2.6311\n",
      "Epoch [2/3000], Loss: 2.7644\n",
      "Epoch [3/3000], Loss: 6.3183\n",
      "Epoch [4/3000], Loss: 5.7213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/3000], Loss: 0.7647\n",
      "Epoch [6/3000], Loss: 0.2034\n",
      "Epoch [7/3000], Loss: 2.7598\n",
      "Epoch [8/3000], Loss: 3.1140\n",
      "Epoch [9/3000], Loss: 3.4557\n",
      "Epoch [10/3000], Loss: 2.8871\n",
      "Epoch [11/3000], Loss: 0.0844\n",
      "Epoch [12/3000], Loss: 4.1512\n",
      "Epoch [13/3000], Loss: 2.0644\n",
      "Epoch [14/3000], Loss: 1.8578\n",
      "Epoch [15/3000], Loss: 3.9929\n",
      "Epoch [16/3000], Loss: 0.1981\n",
      "Epoch [17/3000], Loss: 1.0490\n",
      "Epoch [18/3000], Loss: 0.1628\n",
      "Epoch [19/3000], Loss: 4.5680\n",
      "Epoch [20/3000], Loss: 1.6567\n",
      "Epoch [21/3000], Loss: 0.0734\n",
      "Epoch [22/3000], Loss: 2.1057\n",
      "Epoch [23/3000], Loss: 0.6614\n",
      "Epoch [24/3000], Loss: 1.3769\n",
      "Epoch [25/3000], Loss: 0.2057\n",
      "Epoch [26/3000], Loss: 0.5977\n",
      "Epoch [27/3000], Loss: 1.2610\n",
      "Epoch [28/3000], Loss: 2.3112\n",
      "Epoch [29/3000], Loss: 1.2078\n",
      "Epoch [30/3000], Loss: 0.2598\n",
      "Epoch [31/3000], Loss: 1.4580\n",
      "Epoch [32/3000], Loss: 1.4165\n",
      "Epoch [33/3000], Loss: 0.6700\n",
      "Epoch [34/3000], Loss: 1.6470\n",
      "Epoch [35/3000], Loss: 1.2254\n",
      "Epoch [36/3000], Loss: 2.0288\n",
      "Epoch [37/3000], Loss: 0.3651\n",
      "Epoch [38/3000], Loss: 1.7844\n",
      "Epoch [39/3000], Loss: 1.1649\n",
      "Epoch [40/3000], Loss: 2.9457\n",
      "Epoch [41/3000], Loss: 0.7598\n",
      "Epoch [42/3000], Loss: 1.4043\n",
      "Epoch [43/3000], Loss: 1.1549\n",
      "Epoch [44/3000], Loss: 0.8983\n",
      "Epoch [45/3000], Loss: 1.4187\n",
      "Epoch [46/3000], Loss: 1.2409\n",
      "Epoch [47/3000], Loss: 2.4150\n",
      "Epoch [48/3000], Loss: 2.5766\n",
      "Epoch [49/3000], Loss: 2.7518\n",
      "Epoch [50/3000], Loss: 1.0903\n",
      "Epoch [51/3000], Loss: 1.8209\n",
      "Epoch [52/3000], Loss: 1.6485\n",
      "Epoch [53/3000], Loss: 1.2038\n",
      "Epoch [54/3000], Loss: 1.4736\n",
      "Epoch [55/3000], Loss: 1.4163\n",
      "Epoch [56/3000], Loss: 1.2292\n",
      "Epoch [57/3000], Loss: 1.3857\n",
      "Epoch [58/3000], Loss: 1.5955\n",
      "Epoch [59/3000], Loss: 0.9023\n",
      "Epoch [60/3000], Loss: 1.6389\n",
      "Epoch [61/3000], Loss: 1.0521\n",
      "Epoch [62/3000], Loss: 1.5928\n",
      "Epoch [63/3000], Loss: 0.4760\n",
      "Epoch [64/3000], Loss: 0.4618\n",
      "Epoch [65/3000], Loss: 2.0582\n",
      "Epoch [66/3000], Loss: 1.1119\n",
      "Epoch [67/3000], Loss: 1.2922\n",
      "Epoch [68/3000], Loss: 0.7454\n",
      "Epoch [69/3000], Loss: 1.5106\n",
      "Epoch [70/3000], Loss: 1.3454\n",
      "Epoch [71/3000], Loss: 0.6073\n",
      "Epoch [72/3000], Loss: 2.4168\n",
      "Epoch [73/3000], Loss: 0.5265\n",
      "Epoch [74/3000], Loss: 2.1422\n",
      "Epoch [75/3000], Loss: 1.9107\n",
      "Epoch [76/3000], Loss: 0.9199\n",
      "Epoch [77/3000], Loss: 0.8379\n",
      "Epoch [78/3000], Loss: 1.5195\n",
      "Epoch [79/3000], Loss: 0.6294\n",
      "Epoch [80/3000], Loss: 0.9568\n",
      "Epoch [81/3000], Loss: 0.3313\n",
      "Epoch [82/3000], Loss: 0.7524\n",
      "Epoch [83/3000], Loss: 2.3897\n",
      "Epoch [84/3000], Loss: 1.2239\n",
      "Epoch [85/3000], Loss: 1.3400\n",
      "Epoch [86/3000], Loss: 1.2286\n",
      "Epoch [87/3000], Loss: 0.7554\n",
      "Epoch [88/3000], Loss: 1.1355\n",
      "Epoch [89/3000], Loss: 2.2816\n",
      "Epoch [90/3000], Loss: 0.5177\n",
      "Epoch [91/3000], Loss: 0.7156\n",
      "Epoch [92/3000], Loss: 1.5579\n",
      "Epoch [93/3000], Loss: 0.8921\n",
      "Epoch [94/3000], Loss: 0.7947\n",
      "Epoch [95/3000], Loss: 0.6604\n",
      "Epoch [96/3000], Loss: 1.3607\n",
      "Epoch [97/3000], Loss: 1.7719\n",
      "Epoch [98/3000], Loss: 2.5641\n",
      "Epoch [99/3000], Loss: 1.9665\n",
      "Epoch [100/3000], Loss: 1.2384\n",
      "Epoch [101/3000], Loss: 0.8337\n",
      "Epoch [102/3000], Loss: 1.8648\n",
      "Epoch [103/3000], Loss: 0.8652\n",
      "Epoch [104/3000], Loss: 2.2051\n",
      "Epoch [105/3000], Loss: 0.5069\n",
      "Epoch [106/3000], Loss: 1.5586\n",
      "Epoch [107/3000], Loss: 1.4508\n",
      "Epoch [108/3000], Loss: 2.1388\n",
      "Epoch [109/3000], Loss: 0.6835\n",
      "Epoch [110/3000], Loss: 1.4669\n",
      "Epoch [111/3000], Loss: 1.5368\n",
      "Epoch [112/3000], Loss: 0.1751\n",
      "Epoch [113/3000], Loss: 0.3686\n",
      "Epoch [114/3000], Loss: 0.6484\n",
      "Epoch [115/3000], Loss: 0.7723\n",
      "Epoch [116/3000], Loss: 1.3335\n",
      "Epoch [117/3000], Loss: 1.4725\n",
      "Epoch [118/3000], Loss: 0.8970\n",
      "Epoch [119/3000], Loss: 1.5284\n",
      "Epoch [120/3000], Loss: 1.1580\n",
      "Epoch [121/3000], Loss: 1.6469\n",
      "Epoch [122/3000], Loss: 0.7496\n",
      "Epoch [123/3000], Loss: 1.0167\n",
      "Epoch [124/3000], Loss: 2.0652\n",
      "Epoch [125/3000], Loss: 0.7770\n",
      "Epoch [126/3000], Loss: 0.4681\n",
      "Epoch [127/3000], Loss: 1.8000\n",
      "Epoch [128/3000], Loss: 0.1865\n",
      "Epoch [129/3000], Loss: 2.0584\n",
      "Epoch [130/3000], Loss: 1.3256\n",
      "Epoch [131/3000], Loss: 0.9938\n",
      "Epoch [132/3000], Loss: 0.9468\n",
      "Epoch [133/3000], Loss: 0.2177\n",
      "Epoch [134/3000], Loss: 0.4717\n",
      "Epoch [135/3000], Loss: 0.2006\n",
      "Epoch [136/3000], Loss: 1.7002\n",
      "Epoch [137/3000], Loss: 0.0783\n",
      "Epoch [138/3000], Loss: 1.2714\n",
      "Epoch [139/3000], Loss: 1.7829\n",
      "Epoch [140/3000], Loss: 1.8199\n",
      "Epoch [141/3000], Loss: 1.5078\n",
      "Epoch [142/3000], Loss: 0.6408\n",
      "Epoch [143/3000], Loss: 0.9404\n",
      "Epoch [144/3000], Loss: 1.3345\n",
      "Epoch [145/3000], Loss: 1.5177\n",
      "Epoch [146/3000], Loss: 1.5677\n",
      "Epoch [147/3000], Loss: 0.7475\n",
      "Epoch [148/3000], Loss: 1.2917\n",
      "Epoch [149/3000], Loss: 1.1341\n",
      "Epoch [150/3000], Loss: 0.8007\n",
      "Epoch [151/3000], Loss: 0.8836\n",
      "Epoch [152/3000], Loss: 1.1528\n",
      "Epoch [153/3000], Loss: 1.2393\n",
      "Epoch [154/3000], Loss: 0.1030\n",
      "Epoch [155/3000], Loss: 1.0223\n",
      "Epoch [156/3000], Loss: 2.5449\n",
      "Epoch [157/3000], Loss: 1.1520\n",
      "Epoch [158/3000], Loss: 0.4852\n",
      "Epoch [159/3000], Loss: 2.6439\n",
      "Epoch [160/3000], Loss: 0.8865\n",
      "Epoch [161/3000], Loss: 0.9162\n",
      "Epoch [162/3000], Loss: 1.4606\n",
      "Epoch [163/3000], Loss: 0.0818\n",
      "Epoch [164/3000], Loss: 0.6893\n",
      "Epoch [165/3000], Loss: 2.1430\n",
      "Epoch [166/3000], Loss: 1.7552\n",
      "Epoch [167/3000], Loss: 1.0351\n",
      "Epoch [168/3000], Loss: 0.5979\n",
      "Epoch [169/3000], Loss: 1.7947\n",
      "Epoch [170/3000], Loss: 0.8078\n",
      "Epoch [171/3000], Loss: 1.5948\n",
      "Epoch [172/3000], Loss: 0.4805\n",
      "Epoch [173/3000], Loss: 0.8087\n",
      "Epoch [174/3000], Loss: 0.7250\n",
      "Epoch [175/3000], Loss: 0.7632\n",
      "Epoch [176/3000], Loss: 1.6731\n",
      "Epoch [177/3000], Loss: 1.9736\n",
      "Epoch [178/3000], Loss: 0.2129\n",
      "Epoch [179/3000], Loss: 1.2858\n",
      "Epoch [180/3000], Loss: 1.2489\n",
      "Epoch [181/3000], Loss: 0.7337\n",
      "Epoch [182/3000], Loss: 1.3712\n",
      "Epoch [183/3000], Loss: 0.5393\n",
      "Epoch [184/3000], Loss: 1.7900\n",
      "Epoch [185/3000], Loss: 1.1583\n",
      "Epoch [186/3000], Loss: 0.8580\n",
      "Epoch [187/3000], Loss: 0.7896\n",
      "Epoch [188/3000], Loss: 0.7956\n",
      "Epoch [189/3000], Loss: 2.2043\n",
      "Epoch [190/3000], Loss: 1.7446\n",
      "Epoch [191/3000], Loss: 0.8117\n",
      "Epoch [192/3000], Loss: 0.6656\n",
      "Epoch [193/3000], Loss: 0.7411\n",
      "Epoch [194/3000], Loss: 2.0582\n",
      "Epoch [195/3000], Loss: 0.1940\n",
      "Epoch [196/3000], Loss: 1.4569\n",
      "Epoch [197/3000], Loss: 0.1180\n",
      "Epoch [198/3000], Loss: 0.6136\n",
      "Epoch [199/3000], Loss: 1.0653\n",
      "Epoch [200/3000], Loss: 1.2182\n",
      "Epoch [201/3000], Loss: 1.4669\n",
      "Epoch [202/3000], Loss: 1.7057\n",
      "Epoch [203/3000], Loss: 1.5662\n",
      "Epoch [204/3000], Loss: 1.4136\n",
      "Epoch [205/3000], Loss: 1.0314\n",
      "Epoch [206/3000], Loss: 0.4623\n",
      "Epoch [207/3000], Loss: 0.9338\n",
      "Epoch [208/3000], Loss: 2.3481\n",
      "Epoch [209/3000], Loss: 1.4356\n",
      "Epoch [210/3000], Loss: 1.1787\n",
      "Epoch [211/3000], Loss: 1.5343\n",
      "Epoch [212/3000], Loss: 1.7507\n",
      "Epoch [213/3000], Loss: 1.6757\n",
      "Epoch [214/3000], Loss: 0.8286\n",
      "Epoch [215/3000], Loss: 0.9578\n",
      "Epoch [216/3000], Loss: 1.1459\n",
      "Epoch [217/3000], Loss: 1.7745\n",
      "Epoch [218/3000], Loss: 1.2430\n",
      "Epoch [219/3000], Loss: 1.1160\n",
      "Epoch [220/3000], Loss: 0.8927\n",
      "Epoch [221/3000], Loss: 0.1342\n",
      "Epoch [222/3000], Loss: 1.9150\n",
      "Epoch [223/3000], Loss: 1.3018\n",
      "Epoch [224/3000], Loss: 1.4424\n",
      "Epoch [225/3000], Loss: 1.3315\n",
      "Epoch [226/3000], Loss: 1.2712\n",
      "Epoch [227/3000], Loss: 1.1226\n",
      "Epoch [228/3000], Loss: 1.4276\n",
      "Epoch [229/3000], Loss: 0.6325\n",
      "Epoch [230/3000], Loss: 0.8945\n",
      "Epoch [231/3000], Loss: 0.7446\n",
      "Epoch [232/3000], Loss: 0.2010\n",
      "Epoch [233/3000], Loss: 0.9312\n",
      "Epoch [234/3000], Loss: 0.2100\n",
      "Epoch [235/3000], Loss: 1.9618\n",
      "Epoch [236/3000], Loss: 0.5721\n",
      "Epoch [237/3000], Loss: 1.5918\n",
      "Epoch [238/3000], Loss: 1.2060\n",
      "Epoch [239/3000], Loss: 0.7693\n",
      "Epoch [240/3000], Loss: 0.9320\n",
      "Epoch [241/3000], Loss: 0.9407\n",
      "Epoch [242/3000], Loss: 0.7828\n",
      "Epoch [243/3000], Loss: 0.9731\n",
      "Epoch [244/3000], Loss: 1.1716\n",
      "Epoch [245/3000], Loss: 1.0581\n",
      "Epoch [246/3000], Loss: 1.9527\n",
      "Epoch [247/3000], Loss: 0.6384\n",
      "Epoch [248/3000], Loss: 0.6796\n",
      "Epoch [249/3000], Loss: 0.3554\n",
      "Epoch [250/3000], Loss: 1.3669\n",
      "Epoch [251/3000], Loss: 0.8016\n",
      "Epoch [252/3000], Loss: 0.8955\n",
      "Epoch [253/3000], Loss: 1.4478\n",
      "Epoch [254/3000], Loss: 0.6996\n",
      "Epoch [255/3000], Loss: 0.5735\n",
      "Epoch [256/3000], Loss: 0.1140\n",
      "Epoch [257/3000], Loss: 1.5105\n",
      "Epoch [258/3000], Loss: 0.1845\n",
      "Epoch [259/3000], Loss: 1.2694\n",
      "Epoch [260/3000], Loss: 0.5465\n",
      "Epoch [261/3000], Loss: 0.3307\n",
      "Epoch [262/3000], Loss: 1.4395\n",
      "Epoch [263/3000], Loss: 1.3039\n",
      "Epoch [264/3000], Loss: 0.4649\n",
      "Epoch [265/3000], Loss: 0.5230\n",
      "Epoch [266/3000], Loss: 0.6889\n",
      "Epoch [267/3000], Loss: 1.1796\n",
      "Epoch [268/3000], Loss: 0.9868\n",
      "Epoch [269/3000], Loss: 1.8264\n",
      "Epoch [270/3000], Loss: 0.9844\n",
      "Epoch [271/3000], Loss: 1.0987\n",
      "Epoch [272/3000], Loss: 1.5062\n",
      "Epoch [273/3000], Loss: 0.3587\n",
      "Epoch [274/3000], Loss: 0.8848\n",
      "Epoch [275/3000], Loss: 0.5910\n",
      "Epoch [276/3000], Loss: 0.4895\n",
      "Epoch [277/3000], Loss: 1.3347\n",
      "Epoch [278/3000], Loss: 1.3661\n",
      "Epoch [279/3000], Loss: 1.2442\n",
      "Epoch [280/3000], Loss: 0.5156\n",
      "Epoch [281/3000], Loss: 1.1521\n",
      "Epoch [282/3000], Loss: 0.6731\n",
      "Epoch [283/3000], Loss: 0.2954\n",
      "Epoch [284/3000], Loss: 1.7613\n",
      "Epoch [285/3000], Loss: 0.4999\n",
      "Epoch [286/3000], Loss: 0.7564\n",
      "Epoch [287/3000], Loss: 0.4901\n",
      "Epoch [288/3000], Loss: 0.7331\n",
      "Epoch [289/3000], Loss: 0.9885\n",
      "Epoch [290/3000], Loss: 0.6872\n",
      "Epoch [291/3000], Loss: 0.1517\n",
      "Epoch [292/3000], Loss: 1.6440\n",
      "Epoch [293/3000], Loss: 1.4731\n",
      "Epoch [294/3000], Loss: 1.1245\n",
      "Epoch [295/3000], Loss: 0.4599\n",
      "Epoch [296/3000], Loss: 1.0210\n",
      "Epoch [297/3000], Loss: 0.1263\n",
      "Epoch [298/3000], Loss: 0.1060\n",
      "Epoch [299/3000], Loss: 0.8332\n",
      "Epoch [300/3000], Loss: 1.0762\n",
      "Epoch [301/3000], Loss: 0.6859\n",
      "Epoch [302/3000], Loss: 2.2192\n",
      "Epoch [303/3000], Loss: 1.1676\n",
      "Epoch [304/3000], Loss: 0.4767\n",
      "Epoch [305/3000], Loss: 0.5374\n",
      "Epoch [306/3000], Loss: 1.3313\n",
      "Epoch [307/3000], Loss: 2.4293\n",
      "Epoch [308/3000], Loss: 1.3200\n",
      "Epoch [309/3000], Loss: 0.7809\n",
      "Epoch [310/3000], Loss: 0.3987\n",
      "Epoch [311/3000], Loss: 0.4688\n",
      "Epoch [312/3000], Loss: 0.7809\n",
      "Epoch [313/3000], Loss: 1.9621\n",
      "Epoch [314/3000], Loss: 0.4853\n",
      "Epoch [315/3000], Loss: 1.3012\n",
      "Epoch [316/3000], Loss: 1.2909\n",
      "Epoch [317/3000], Loss: 0.9665\n",
      "Epoch [318/3000], Loss: 0.6767\n",
      "Epoch [319/3000], Loss: 0.7171\n",
      "Epoch [320/3000], Loss: 0.4030\n",
      "Epoch [321/3000], Loss: 1.0498\n",
      "Epoch [322/3000], Loss: 0.6621\n",
      "Epoch [323/3000], Loss: 0.4820\n",
      "Epoch [324/3000], Loss: 1.1430\n",
      "Epoch [325/3000], Loss: 1.3128\n",
      "Epoch [326/3000], Loss: 0.4819\n",
      "Epoch [327/3000], Loss: 0.8090\n",
      "Epoch [328/3000], Loss: 0.0565\n",
      "Epoch [329/3000], Loss: 0.5130\n",
      "Epoch [330/3000], Loss: 0.6314\n",
      "Epoch [331/3000], Loss: 0.3852\n",
      "Epoch [332/3000], Loss: 0.5623\n",
      "Epoch [333/3000], Loss: 1.5913\n",
      "Epoch [334/3000], Loss: 1.6601\n",
      "Epoch [335/3000], Loss: 1.0018\n",
      "Epoch [336/3000], Loss: 0.5526\n",
      "Epoch [337/3000], Loss: 0.6181\n",
      "Epoch [338/3000], Loss: 1.2059\n",
      "Epoch [339/3000], Loss: 0.2245\n",
      "Epoch [340/3000], Loss: 1.5664\n",
      "Epoch [341/3000], Loss: 1.5120\n",
      "Epoch [342/3000], Loss: 1.7516\n",
      "Epoch [343/3000], Loss: 0.2133\n",
      "Epoch [344/3000], Loss: 0.5637\n",
      "Epoch [345/3000], Loss: 2.2907\n",
      "Epoch [346/3000], Loss: 0.9216\n",
      "Epoch [347/3000], Loss: 0.8189\n",
      "Epoch [348/3000], Loss: 0.6561\n",
      "Epoch [349/3000], Loss: 0.6304\n",
      "Epoch [350/3000], Loss: 0.7225\n",
      "Epoch [351/3000], Loss: 1.2176\n",
      "Epoch [352/3000], Loss: 0.4951\n",
      "Epoch [353/3000], Loss: 0.5662\n",
      "Epoch [354/3000], Loss: 1.1431\n",
      "Epoch [355/3000], Loss: 1.0884\n",
      "Epoch [356/3000], Loss: 0.2457\n",
      "Epoch [357/3000], Loss: 0.6775\n",
      "Epoch [358/3000], Loss: 0.4275\n",
      "Epoch [359/3000], Loss: 0.2330\n",
      "Epoch [360/3000], Loss: 0.9864\n",
      "Epoch [361/3000], Loss: 1.4337\n",
      "Epoch [362/3000], Loss: 1.1395\n",
      "Epoch [363/3000], Loss: 1.1844\n",
      "Epoch [364/3000], Loss: 0.7059\n",
      "Epoch [365/3000], Loss: 2.0019\n",
      "Epoch [366/3000], Loss: 0.8679\n",
      "Epoch [367/3000], Loss: 1.3912\n",
      "Epoch [368/3000], Loss: 1.5911\n",
      "Epoch [369/3000], Loss: 0.0465\n",
      "Epoch [370/3000], Loss: 1.4676\n",
      "Epoch [371/3000], Loss: 0.9109\n",
      "Epoch [372/3000], Loss: 0.7435\n",
      "Epoch [373/3000], Loss: 2.1316\n",
      "Epoch [374/3000], Loss: 0.8529\n",
      "Epoch [375/3000], Loss: 1.7772\n",
      "Epoch [376/3000], Loss: 0.4470\n",
      "Epoch [377/3000], Loss: 0.8025\n",
      "Epoch [378/3000], Loss: 1.2775\n",
      "Epoch [379/3000], Loss: 0.2972\n",
      "Epoch [380/3000], Loss: 1.4090\n",
      "Epoch [381/3000], Loss: 1.5498\n",
      "Epoch [382/3000], Loss: 1.4713\n",
      "Epoch [383/3000], Loss: 0.5400\n",
      "Epoch [384/3000], Loss: 1.2596\n",
      "Epoch [385/3000], Loss: 0.3391\n",
      "Epoch [386/3000], Loss: 1.6986\n",
      "Epoch [387/3000], Loss: 0.5286\n",
      "Epoch [388/3000], Loss: 0.8234\n",
      "Epoch [389/3000], Loss: 1.5944\n",
      "Epoch [390/3000], Loss: 0.3856\n",
      "Epoch [391/3000], Loss: 1.5687\n",
      "Epoch [392/3000], Loss: 1.5654\n",
      "Epoch [393/3000], Loss: 0.4568\n",
      "Epoch [394/3000], Loss: 2.6865\n",
      "Epoch [395/3000], Loss: 1.0231\n",
      "Epoch [396/3000], Loss: 0.7767\n",
      "Epoch [397/3000], Loss: 0.6010\n",
      "Epoch [398/3000], Loss: 0.5399\n",
      "Epoch [399/3000], Loss: 0.6520\n",
      "Epoch [400/3000], Loss: 1.1397\n",
      "Epoch [401/3000], Loss: 0.8216\n",
      "Epoch [402/3000], Loss: 0.5662\n",
      "Epoch [403/3000], Loss: 0.3257\n",
      "Epoch [404/3000], Loss: 0.7117\n",
      "Epoch [405/3000], Loss: 1.8278\n",
      "Epoch [406/3000], Loss: 0.7266\n",
      "Epoch [407/3000], Loss: 0.4787\n",
      "Epoch [408/3000], Loss: 0.7979\n",
      "Epoch [409/3000], Loss: 0.4139\n",
      "Epoch [410/3000], Loss: 0.0897\n",
      "Epoch [411/3000], Loss: 0.4430\n",
      "Epoch [412/3000], Loss: 0.5437\n",
      "Epoch [413/3000], Loss: 0.8701\n",
      "Epoch [414/3000], Loss: 1.1251\n",
      "Epoch [415/3000], Loss: 0.1020\n",
      "Epoch [416/3000], Loss: 0.3527\n",
      "Epoch [417/3000], Loss: 1.5178\n",
      "Epoch [418/3000], Loss: 0.7141\n",
      "Epoch [419/3000], Loss: 0.7072\n",
      "Epoch [420/3000], Loss: 0.3176\n",
      "Epoch [421/3000], Loss: 0.2381\n",
      "Epoch [422/3000], Loss: 0.5216\n",
      "Epoch [423/3000], Loss: 1.1301\n",
      "Epoch [424/3000], Loss: 1.0943\n",
      "Epoch [425/3000], Loss: 0.5210\n",
      "Epoch [426/3000], Loss: 0.5967\n",
      "Epoch [427/3000], Loss: 0.8850\n",
      "Epoch [428/3000], Loss: 0.4229\n",
      "Epoch [429/3000], Loss: 0.6270\n",
      "Epoch [430/3000], Loss: 0.6428\n",
      "Epoch [431/3000], Loss: 0.4853\n",
      "Epoch [432/3000], Loss: 0.8808\n",
      "Epoch [433/3000], Loss: 0.6839\n",
      "Epoch [434/3000], Loss: 0.4670\n",
      "Epoch [435/3000], Loss: 0.1445\n",
      "Epoch [436/3000], Loss: 0.5454\n",
      "Epoch [437/3000], Loss: 1.4887\n",
      "Epoch [438/3000], Loss: 0.4529\n",
      "Epoch [439/3000], Loss: 1.0307\n",
      "Epoch [440/3000], Loss: 0.5353\n",
      "Epoch [441/3000], Loss: 0.3476\n",
      "Epoch [442/3000], Loss: 2.0361\n",
      "Epoch [443/3000], Loss: 0.3447\n",
      "Epoch [444/3000], Loss: 0.8627\n",
      "Epoch [445/3000], Loss: 1.3656\n",
      "Epoch [446/3000], Loss: 0.4020\n",
      "Epoch [447/3000], Loss: 2.4938\n",
      "Epoch [448/3000], Loss: 1.0183\n",
      "Epoch [449/3000], Loss: 1.2719\n",
      "Epoch [450/3000], Loss: 1.0007\n",
      "Epoch [451/3000], Loss: 0.7723\n",
      "Epoch [452/3000], Loss: 2.0709\n",
      "Epoch [453/3000], Loss: 0.4556\n",
      "Epoch [454/3000], Loss: 0.7771\n",
      "Epoch [455/3000], Loss: 0.8821\n",
      "Epoch [456/3000], Loss: 1.6183\n",
      "Epoch [457/3000], Loss: 0.4148\n",
      "Epoch [458/3000], Loss: 1.0560\n",
      "Epoch [459/3000], Loss: 0.8063\n",
      "Epoch [460/3000], Loss: 1.3905\n",
      "Epoch [461/3000], Loss: 0.5932\n",
      "Epoch [462/3000], Loss: 0.8143\n",
      "Epoch [463/3000], Loss: 0.1424\n",
      "Epoch [464/3000], Loss: 0.9301\n",
      "Epoch [465/3000], Loss: 0.8559\n",
      "Epoch [466/3000], Loss: 0.3657\n",
      "Epoch [467/3000], Loss: 0.9105\n",
      "Epoch [468/3000], Loss: 0.3256\n",
      "Epoch [469/3000], Loss: 0.6047\n",
      "Epoch [470/3000], Loss: 0.4777\n",
      "Epoch [471/3000], Loss: 0.5652\n",
      "Epoch [472/3000], Loss: 1.5885\n",
      "Epoch [473/3000], Loss: 0.8367\n",
      "Epoch [474/3000], Loss: 0.7277\n",
      "Epoch [475/3000], Loss: 0.2817\n",
      "Epoch [476/3000], Loss: 0.9374\n",
      "Epoch [477/3000], Loss: 0.7856\n",
      "Epoch [478/3000], Loss: 0.6196\n",
      "Epoch [479/3000], Loss: 0.4838\n",
      "Epoch [480/3000], Loss: 0.3858\n",
      "Epoch [481/3000], Loss: 1.9472\n",
      "Epoch [482/3000], Loss: 0.1402\n",
      "Epoch [483/3000], Loss: 1.5758\n",
      "Epoch [484/3000], Loss: 0.3531\n",
      "Epoch [485/3000], Loss: 0.0951\n",
      "Epoch [486/3000], Loss: 0.6511\n",
      "Epoch [487/3000], Loss: 2.3013\n",
      "Epoch [488/3000], Loss: 0.8955\n",
      "Epoch [489/3000], Loss: 0.9445\n",
      "Epoch [490/3000], Loss: 0.1273\n",
      "Epoch [491/3000], Loss: 0.5418\n",
      "Epoch [492/3000], Loss: 0.5900\n",
      "Epoch [493/3000], Loss: 0.7555\n",
      "Epoch [494/3000], Loss: 0.5207\n",
      "Epoch [495/3000], Loss: 0.9800\n",
      "Epoch [496/3000], Loss: 0.3312\n",
      "Epoch [497/3000], Loss: 1.2840\n",
      "Epoch [498/3000], Loss: 1.0580\n",
      "Epoch [499/3000], Loss: 2.0180\n",
      "Epoch [500/3000], Loss: 0.8174\n",
      "Epoch [501/3000], Loss: 0.2642\n",
      "Epoch [502/3000], Loss: 0.4249\n",
      "Epoch [503/3000], Loss: 0.5678\n",
      "Epoch [504/3000], Loss: 0.8389\n",
      "Epoch [505/3000], Loss: 0.6032\n",
      "Epoch [506/3000], Loss: 0.3014\n",
      "Epoch [507/3000], Loss: 0.6899\n",
      "Epoch [508/3000], Loss: 2.0846\n",
      "Epoch [509/3000], Loss: 1.5656\n",
      "Epoch [510/3000], Loss: 0.6294\n",
      "Epoch [511/3000], Loss: 1.4609\n",
      "Epoch [512/3000], Loss: 0.3100\n",
      "Epoch [513/3000], Loss: 0.5272\n",
      "Epoch [514/3000], Loss: 0.4116\n",
      "Epoch [515/3000], Loss: 0.7009\n",
      "Epoch [516/3000], Loss: 0.3031\n",
      "Epoch [517/3000], Loss: 0.3618\n",
      "Epoch [518/3000], Loss: 0.6872\n",
      "Epoch [519/3000], Loss: 0.6365\n",
      "Epoch [520/3000], Loss: 1.1483\n",
      "Epoch [521/3000], Loss: 1.0214\n",
      "Epoch [522/3000], Loss: 0.4849\n",
      "Epoch [523/3000], Loss: 0.8155\n",
      "Epoch [524/3000], Loss: 2.8596\n",
      "Epoch [525/3000], Loss: 0.4680\n",
      "Epoch [526/3000], Loss: 0.1590\n",
      "Epoch [527/3000], Loss: 0.4550\n",
      "Epoch [528/3000], Loss: 0.5221\n",
      "Epoch [529/3000], Loss: 0.7818\n",
      "Epoch [530/3000], Loss: 0.7368\n",
      "Epoch [531/3000], Loss: 1.0249\n",
      "Epoch [532/3000], Loss: 0.8932\n",
      "Epoch [533/3000], Loss: 1.0690\n",
      "Epoch [534/3000], Loss: 0.7298\n",
      "Epoch [535/3000], Loss: 0.4795\n",
      "Epoch [536/3000], Loss: 0.8734\n",
      "Epoch [537/3000], Loss: 0.7793\n",
      "Epoch [538/3000], Loss: 1.1198\n",
      "Epoch [539/3000], Loss: 1.3574\n",
      "Epoch [540/3000], Loss: 0.5361\n",
      "Epoch [541/3000], Loss: 0.3264\n",
      "Epoch [542/3000], Loss: 0.5288\n",
      "Epoch [543/3000], Loss: 1.0479\n",
      "Epoch [544/3000], Loss: 1.0275\n",
      "Epoch [545/3000], Loss: 0.5523\n",
      "Epoch [546/3000], Loss: 3.0011\n",
      "Epoch [547/3000], Loss: 0.6330\n",
      "Epoch [548/3000], Loss: 0.7915\n",
      "Epoch [549/3000], Loss: 0.7845\n",
      "Epoch [550/3000], Loss: 0.9326\n",
      "Epoch [551/3000], Loss: 0.5570\n",
      "Epoch [552/3000], Loss: 0.5968\n",
      "Epoch [553/3000], Loss: 0.6496\n",
      "Epoch [554/3000], Loss: 0.3178\n",
      "Epoch [555/3000], Loss: 0.0650\n",
      "Epoch [556/3000], Loss: 1.5663\n",
      "Epoch [557/3000], Loss: 1.6449\n",
      "Epoch [558/3000], Loss: 1.0549\n",
      "Epoch [559/3000], Loss: 0.5778\n",
      "Epoch [560/3000], Loss: 0.2288\n",
      "Epoch [561/3000], Loss: 1.2111\n",
      "Epoch [562/3000], Loss: 0.2684\n",
      "Epoch [563/3000], Loss: 0.4120\n",
      "Epoch [564/3000], Loss: 1.1499\n",
      "Epoch [565/3000], Loss: 1.7540\n",
      "Epoch [566/3000], Loss: 2.1516\n",
      "Epoch [567/3000], Loss: 0.8864\n",
      "Epoch [568/3000], Loss: 0.0676\n",
      "Epoch [569/3000], Loss: 0.6651\n",
      "Epoch [570/3000], Loss: 1.0363\n",
      "Epoch [571/3000], Loss: 0.3198\n",
      "Epoch [572/3000], Loss: 1.1382\n",
      "Epoch [573/3000], Loss: 0.0698\n",
      "Epoch [574/3000], Loss: 1.3965\n",
      "Epoch [575/3000], Loss: 1.9567\n",
      "Epoch [576/3000], Loss: 1.0150\n",
      "Epoch [577/3000], Loss: 1.0455\n",
      "Epoch [578/3000], Loss: 0.7061\n",
      "Epoch [579/3000], Loss: 0.6238\n",
      "Epoch [580/3000], Loss: 1.5745\n",
      "Epoch [581/3000], Loss: 0.5157\n",
      "Epoch [582/3000], Loss: 0.3430\n",
      "Epoch [583/3000], Loss: 1.3867\n",
      "Epoch [584/3000], Loss: 0.7510\n",
      "Epoch [585/3000], Loss: 0.7560\n",
      "Epoch [586/3000], Loss: 0.7699\n",
      "Epoch [587/3000], Loss: 0.7717\n",
      "Epoch [588/3000], Loss: 0.2885\n",
      "Epoch [589/3000], Loss: 1.3019\n",
      "Epoch [590/3000], Loss: 1.0087\n",
      "Epoch [591/3000], Loss: 1.2576\n",
      "Epoch [592/3000], Loss: 0.6053\n",
      "Epoch [593/3000], Loss: 0.4608\n",
      "Epoch [594/3000], Loss: 1.5363\n",
      "Epoch [595/3000], Loss: 1.5212\n",
      "Epoch [596/3000], Loss: 0.7554\n",
      "Epoch [597/3000], Loss: 1.1579\n",
      "Epoch [598/3000], Loss: 0.8199\n",
      "Epoch [599/3000], Loss: 0.5257\n",
      "Epoch [600/3000], Loss: 0.6321\n",
      "Epoch [601/3000], Loss: 0.6383\n",
      "Epoch [602/3000], Loss: 0.7353\n",
      "Epoch [603/3000], Loss: 1.2121\n",
      "Epoch [604/3000], Loss: 0.4577\n",
      "Epoch [605/3000], Loss: 0.7821\n",
      "Epoch [606/3000], Loss: 0.4713\n",
      "Epoch [607/3000], Loss: 1.1606\n",
      "Epoch [608/3000], Loss: 1.8680\n",
      "Epoch [609/3000], Loss: 1.1629\n",
      "Epoch [610/3000], Loss: 0.4974\n",
      "Epoch [611/3000], Loss: 0.8414\n",
      "Epoch [612/3000], Loss: 0.7423\n",
      "Epoch [613/3000], Loss: 1.3436\n",
      "Epoch [614/3000], Loss: 0.6330\n",
      "Epoch [615/3000], Loss: 0.9199\n",
      "Epoch [616/3000], Loss: 0.6064\n",
      "Epoch [617/3000], Loss: 0.3083\n",
      "Epoch [618/3000], Loss: 0.7299\n",
      "Epoch [619/3000], Loss: 0.5248\n",
      "Epoch [620/3000], Loss: 0.7353\n",
      "Epoch [621/3000], Loss: 0.8612\n",
      "Epoch [622/3000], Loss: 2.8848\n",
      "Epoch [623/3000], Loss: 0.6284\n",
      "Epoch [624/3000], Loss: 0.4074\n",
      "Epoch [625/3000], Loss: 1.2094\n",
      "Epoch [626/3000], Loss: 1.0861\n",
      "Epoch [627/3000], Loss: 0.4070\n",
      "Epoch [628/3000], Loss: 1.3833\n",
      "Epoch [629/3000], Loss: 2.0774\n",
      "Epoch [630/3000], Loss: 0.7152\n",
      "Epoch [631/3000], Loss: 0.2345\n",
      "Epoch [632/3000], Loss: 0.4012\n",
      "Epoch [633/3000], Loss: 0.2087\n",
      "Epoch [634/3000], Loss: 0.9718\n",
      "Epoch [635/3000], Loss: 1.0803\n",
      "Epoch [636/3000], Loss: 2.3662\n",
      "Epoch [637/3000], Loss: 0.5931\n",
      "Epoch [638/3000], Loss: 0.4139\n",
      "Epoch [639/3000], Loss: 1.2572\n",
      "Epoch [640/3000], Loss: 0.7179\n",
      "Epoch [641/3000], Loss: 0.3744\n",
      "Epoch [642/3000], Loss: 1.7320\n",
      "Epoch [643/3000], Loss: 0.4712\n",
      "Epoch [644/3000], Loss: 1.6923\n",
      "Epoch [645/3000], Loss: 1.3084\n",
      "Epoch [646/3000], Loss: 0.8055\n",
      "Epoch [647/3000], Loss: 0.4893\n",
      "Epoch [648/3000], Loss: 0.8646\n",
      "Epoch [649/3000], Loss: 0.3407\n",
      "Epoch [650/3000], Loss: 2.4624\n",
      "Epoch [651/3000], Loss: 0.7452\n",
      "Epoch [652/3000], Loss: 0.5943\n",
      "Epoch [653/3000], Loss: 0.6293\n",
      "Epoch [654/3000], Loss: 0.1459\n",
      "Epoch [655/3000], Loss: 0.7993\n",
      "Epoch [656/3000], Loss: 0.3780\n",
      "Epoch [657/3000], Loss: 1.8218\n",
      "Epoch [658/3000], Loss: 1.9689\n",
      "Epoch [659/3000], Loss: 0.1883\n",
      "Epoch [660/3000], Loss: 0.9915\n",
      "Epoch [661/3000], Loss: 0.3251\n",
      "Epoch [662/3000], Loss: 0.3530\n",
      "Epoch [663/3000], Loss: 1.2289\n",
      "Epoch [664/3000], Loss: 2.4262\n",
      "Epoch [665/3000], Loss: 1.9476\n",
      "Epoch [666/3000], Loss: 0.5945\n",
      "Epoch [667/3000], Loss: 2.1092\n",
      "Epoch [668/3000], Loss: 0.8437\n",
      "Epoch [669/3000], Loss: 0.3074\n",
      "Epoch [670/3000], Loss: 0.3303\n",
      "Epoch [671/3000], Loss: 0.9551\n",
      "Epoch [672/3000], Loss: 0.7972\n",
      "Epoch [673/3000], Loss: 0.6204\n",
      "Epoch [674/3000], Loss: 1.0405\n",
      "Epoch [675/3000], Loss: 2.4750\n",
      "Epoch [676/3000], Loss: 0.4273\n",
      "Epoch [677/3000], Loss: 1.3091\n",
      "Epoch [678/3000], Loss: 0.7078\n",
      "Epoch [679/3000], Loss: 0.5398\n",
      "Epoch [680/3000], Loss: 1.2385\n",
      "Epoch [681/3000], Loss: 1.0040\n",
      "Epoch [682/3000], Loss: 0.9746\n",
      "Epoch [683/3000], Loss: 0.5070\n",
      "Epoch [684/3000], Loss: 0.0914\n",
      "Epoch [685/3000], Loss: 0.6753\n",
      "Epoch [686/3000], Loss: 0.6352\n",
      "Epoch [687/3000], Loss: 1.7745\n",
      "Epoch [688/3000], Loss: 1.8200\n",
      "Epoch [689/3000], Loss: 0.3942\n",
      "Epoch [690/3000], Loss: 0.0334\n",
      "Epoch [691/3000], Loss: 0.5658\n",
      "Epoch [692/3000], Loss: 0.9648\n",
      "Epoch [693/3000], Loss: 1.1602\n",
      "Epoch [694/3000], Loss: 1.7451\n",
      "Epoch [695/3000], Loss: 0.7477\n",
      "Epoch [696/3000], Loss: 0.4488\n",
      "Epoch [697/3000], Loss: 0.1180\n",
      "Epoch [698/3000], Loss: 1.8241\n",
      "Epoch [699/3000], Loss: 0.5215\n",
      "Epoch [700/3000], Loss: 1.0868\n",
      "Epoch [701/3000], Loss: 0.4419\n",
      "Epoch [702/3000], Loss: 0.0621\n",
      "Epoch [703/3000], Loss: 1.8679\n",
      "Epoch [704/3000], Loss: 0.4758\n",
      "Epoch [705/3000], Loss: 0.4666\n",
      "Epoch [706/3000], Loss: 2.0733\n",
      "Epoch [707/3000], Loss: 0.1639\n",
      "Epoch [708/3000], Loss: 0.4775\n",
      "Epoch [709/3000], Loss: 0.5456\n",
      "Epoch [710/3000], Loss: 0.6046\n",
      "Epoch [711/3000], Loss: 0.8233\n",
      "Epoch [712/3000], Loss: 1.8580\n",
      "Epoch [713/3000], Loss: 0.0303\n",
      "Epoch [714/3000], Loss: 0.9026\n",
      "Epoch [715/3000], Loss: 0.5419\n",
      "Epoch [716/3000], Loss: 0.1167\n",
      "Epoch [717/3000], Loss: 0.9246\n",
      "Epoch [718/3000], Loss: 0.6887\n",
      "Epoch [719/3000], Loss: 0.1104\n",
      "Epoch [720/3000], Loss: 0.2807\n",
      "Epoch [721/3000], Loss: 0.0468\n",
      "Epoch [722/3000], Loss: 0.5032\n",
      "Epoch [723/3000], Loss: 1.0078\n",
      "Epoch [724/3000], Loss: 0.2383\n",
      "Epoch [725/3000], Loss: 0.8912\n",
      "Epoch [726/3000], Loss: 0.3819\n",
      "Epoch [727/3000], Loss: 1.0654\n",
      "Epoch [728/3000], Loss: 1.3193\n",
      "Epoch [729/3000], Loss: 0.7184\n",
      "Epoch [730/3000], Loss: 0.7901\n",
      "Epoch [731/3000], Loss: 0.9052\n",
      "Epoch [732/3000], Loss: 0.3820\n",
      "Epoch [733/3000], Loss: 1.5230\n",
      "Epoch [734/3000], Loss: 0.8386\n",
      "Epoch [735/3000], Loss: 0.8817\n",
      "Epoch [736/3000], Loss: 0.2948\n",
      "Epoch [737/3000], Loss: 0.2644\n",
      "Epoch [738/3000], Loss: 0.3129\n",
      "Epoch [739/3000], Loss: 1.2803\n",
      "Epoch [740/3000], Loss: 0.9359\n",
      "Epoch [741/3000], Loss: 1.6709\n",
      "Epoch [742/3000], Loss: 0.4365\n",
      "Epoch [743/3000], Loss: 0.0371\n",
      "Epoch [744/3000], Loss: 1.0117\n",
      "Epoch [745/3000], Loss: 1.2785\n",
      "Epoch [746/3000], Loss: 0.4402\n",
      "Epoch [747/3000], Loss: 1.0768\n",
      "Epoch [748/3000], Loss: 1.1533\n",
      "Epoch [749/3000], Loss: 2.0918\n",
      "Epoch [750/3000], Loss: 0.3136\n",
      "Epoch [751/3000], Loss: 0.7127\n",
      "Epoch [752/3000], Loss: 0.7848\n",
      "Epoch [753/3000], Loss: 0.0913\n",
      "Epoch [754/3000], Loss: 0.4395\n",
      "Epoch [755/3000], Loss: 1.7545\n",
      "Epoch [756/3000], Loss: 0.0837\n",
      "Epoch [757/3000], Loss: 0.1953\n",
      "Epoch [758/3000], Loss: 3.0101\n",
      "Epoch [759/3000], Loss: 0.2533\n",
      "Epoch [760/3000], Loss: 0.8238\n",
      "Epoch [761/3000], Loss: 2.0057\n",
      "Epoch [762/3000], Loss: 0.3819\n",
      "Epoch [763/3000], Loss: 0.4239\n",
      "Epoch [764/3000], Loss: 0.3642\n",
      "Epoch [765/3000], Loss: 0.1399\n",
      "Epoch [766/3000], Loss: 0.5444\n",
      "Epoch [767/3000], Loss: 0.8980\n",
      "Epoch [768/3000], Loss: 1.1525\n",
      "Epoch [769/3000], Loss: 1.5466\n",
      "Epoch [770/3000], Loss: 0.2348\n",
      "Epoch [771/3000], Loss: 0.5713\n",
      "Epoch [772/3000], Loss: 1.9263\n",
      "Epoch [773/3000], Loss: 0.7240\n",
      "Epoch [774/3000], Loss: 0.5756\n",
      "Epoch [775/3000], Loss: 0.8860\n",
      "Epoch [776/3000], Loss: 0.7443\n",
      "Epoch [777/3000], Loss: 0.6396\n",
      "Epoch [778/3000], Loss: 1.2126\n",
      "Epoch [779/3000], Loss: 0.6997\n",
      "Epoch [780/3000], Loss: 1.1850\n",
      "Epoch [781/3000], Loss: 0.7471\n",
      "Epoch [782/3000], Loss: 2.1715\n",
      "Epoch [783/3000], Loss: 0.5438\n",
      "Epoch [784/3000], Loss: 0.9961\n",
      "Epoch [785/3000], Loss: 1.9275\n",
      "Epoch [786/3000], Loss: 0.9368\n",
      "Epoch [787/3000], Loss: 0.5621\n",
      "Epoch [788/3000], Loss: 0.5127\n",
      "Epoch [789/3000], Loss: 0.0824\n",
      "Epoch [790/3000], Loss: 0.7036\n",
      "Epoch [791/3000], Loss: 1.1433\n",
      "Epoch [792/3000], Loss: 1.0090\n",
      "Epoch [793/3000], Loss: 0.4960\n",
      "Epoch [794/3000], Loss: 0.3472\n",
      "Epoch [795/3000], Loss: 0.1815\n",
      "Epoch [796/3000], Loss: 0.6172\n",
      "Epoch [797/3000], Loss: 0.1907\n",
      "Epoch [798/3000], Loss: 0.8011\n",
      "Epoch [799/3000], Loss: 0.2808\n",
      "Epoch [800/3000], Loss: 0.9228\n",
      "Epoch [801/3000], Loss: 0.7477\n",
      "Epoch [802/3000], Loss: 0.8188\n",
      "Epoch [803/3000], Loss: 0.9696\n",
      "Epoch [804/3000], Loss: 0.7317\n",
      "Epoch [805/3000], Loss: 1.8645\n",
      "Epoch [806/3000], Loss: 0.6882\n",
      "Epoch [807/3000], Loss: 0.3959\n",
      "Epoch [808/3000], Loss: 0.0089\n",
      "Epoch [809/3000], Loss: 1.9027\n",
      "Epoch [810/3000], Loss: 0.3774\n",
      "Epoch [811/3000], Loss: 1.0890\n",
      "Epoch [812/3000], Loss: 0.8320\n",
      "Epoch [813/3000], Loss: 0.1476\n",
      "Epoch [814/3000], Loss: 0.6199\n",
      "Epoch [815/3000], Loss: 0.5575\n",
      "Epoch [816/3000], Loss: 0.2585\n",
      "Epoch [817/3000], Loss: 0.5378\n",
      "Epoch [818/3000], Loss: 0.1514\n",
      "Epoch [819/3000], Loss: 0.2669\n",
      "Epoch [820/3000], Loss: 1.1830\n",
      "Epoch [821/3000], Loss: 0.5744\n",
      "Epoch [822/3000], Loss: 0.5556\n",
      "Epoch [823/3000], Loss: 1.6576\n",
      "Epoch [824/3000], Loss: 0.5263\n",
      "Epoch [825/3000], Loss: 0.6526\n",
      "Epoch [826/3000], Loss: 0.3513\n",
      "Epoch [827/3000], Loss: 0.7000\n",
      "Epoch [828/3000], Loss: 0.2801\n",
      "Epoch [829/3000], Loss: 0.3693\n",
      "Epoch [830/3000], Loss: 0.6281\n",
      "Epoch [831/3000], Loss: 1.0461\n",
      "Epoch [832/3000], Loss: 2.1492\n",
      "Epoch [833/3000], Loss: 1.8675\n",
      "Epoch [834/3000], Loss: 0.8952\n",
      "Epoch [835/3000], Loss: 0.2067\n",
      "Epoch [836/3000], Loss: 0.1434\n",
      "Epoch [837/3000], Loss: 2.6480\n",
      "Epoch [838/3000], Loss: 0.4645\n",
      "Epoch [839/3000], Loss: 0.3546\n",
      "Epoch [840/3000], Loss: 2.4449\n",
      "Epoch [841/3000], Loss: 0.8152\n",
      "Epoch [842/3000], Loss: 0.3493\n",
      "Epoch [843/3000], Loss: 0.8714\n",
      "Epoch [844/3000], Loss: 0.5499\n",
      "Epoch [845/3000], Loss: 0.6219\n",
      "Epoch [846/3000], Loss: 0.0270\n",
      "Epoch [847/3000], Loss: 0.5859\n",
      "Epoch [848/3000], Loss: 0.9554\n",
      "Epoch [849/3000], Loss: 0.4379\n",
      "Epoch [850/3000], Loss: 1.1817\n",
      "Epoch [851/3000], Loss: 0.3019\n",
      "Epoch [852/3000], Loss: 0.1065\n",
      "Epoch [853/3000], Loss: 0.1640\n",
      "Epoch [854/3000], Loss: 0.6174\n",
      "Epoch [855/3000], Loss: 0.3770\n",
      "Epoch [856/3000], Loss: 0.2570\n",
      "Epoch [857/3000], Loss: 0.7951\n",
      "Epoch [858/3000], Loss: 0.1546\n",
      "Epoch [859/3000], Loss: 1.0797\n",
      "Epoch [860/3000], Loss: 0.8535\n",
      "Epoch [861/3000], Loss: 1.2787\n",
      "Epoch [862/3000], Loss: 0.2287\n",
      "Epoch [863/3000], Loss: 0.2584\n",
      "Epoch [864/3000], Loss: 0.4077\n",
      "Epoch [865/3000], Loss: 0.7246\n",
      "Epoch [866/3000], Loss: 0.7760\n",
      "Epoch [867/3000], Loss: 0.5726\n",
      "Epoch [868/3000], Loss: 0.3727\n",
      "Epoch [869/3000], Loss: 0.4818\n",
      "Epoch [870/3000], Loss: 0.4005\n",
      "Epoch [871/3000], Loss: 0.2897\n",
      "Epoch [872/3000], Loss: 0.5073\n",
      "Epoch [873/3000], Loss: 0.2238\n",
      "Epoch [874/3000], Loss: 0.1826\n",
      "Epoch [875/3000], Loss: 0.2530\n",
      "Epoch [876/3000], Loss: 0.9989\n",
      "Epoch [877/3000], Loss: 1.0769\n",
      "Epoch [878/3000], Loss: 0.7005\n",
      "Epoch [879/3000], Loss: 0.2775\n",
      "Epoch [880/3000], Loss: 1.0517\n",
      "Epoch [881/3000], Loss: 1.2891\n",
      "Epoch [882/3000], Loss: 0.5117\n",
      "Epoch [883/3000], Loss: 0.4470\n",
      "Epoch [884/3000], Loss: 3.6127\n",
      "Epoch [885/3000], Loss: 1.6050\n",
      "Epoch [886/3000], Loss: 0.4482\n",
      "Epoch [887/3000], Loss: 1.6242\n",
      "Epoch [888/3000], Loss: 0.6519\n",
      "Epoch [889/3000], Loss: 1.0570\n",
      "Epoch [890/3000], Loss: 0.7967\n",
      "Epoch [891/3000], Loss: 0.2107\n",
      "Epoch [892/3000], Loss: 0.2279\n",
      "Epoch [893/3000], Loss: 1.0255\n",
      "Epoch [894/3000], Loss: 0.7321\n",
      "Epoch [895/3000], Loss: 1.3079\n",
      "Epoch [896/3000], Loss: 1.8460\n",
      "Epoch [897/3000], Loss: 0.7045\n",
      "Epoch [898/3000], Loss: 0.3305\n",
      "Epoch [899/3000], Loss: 0.2225\n",
      "Epoch [900/3000], Loss: 0.8644\n",
      "Epoch [901/3000], Loss: 0.3702\n",
      "Epoch [902/3000], Loss: 0.0390\n",
      "Epoch [903/3000], Loss: 0.7036\n",
      "Epoch [904/3000], Loss: 0.3091\n",
      "Epoch [905/3000], Loss: 0.4764\n",
      "Epoch [906/3000], Loss: 0.1707\n",
      "Epoch [907/3000], Loss: 0.4407\n",
      "Epoch [908/3000], Loss: 0.8873\n",
      "Epoch [909/3000], Loss: 0.0325\n",
      "Epoch [910/3000], Loss: 0.5908\n",
      "Epoch [911/3000], Loss: 0.9699\n",
      "Epoch [912/3000], Loss: 1.5706\n",
      "Epoch [913/3000], Loss: 0.2602\n",
      "Epoch [914/3000], Loss: 0.3054\n",
      "Epoch [915/3000], Loss: 0.2873\n",
      "Epoch [916/3000], Loss: 0.1810\n",
      "Epoch [917/3000], Loss: 0.2257\n",
      "Epoch [918/3000], Loss: 0.3127\n",
      "Epoch [919/3000], Loss: 0.1674\n",
      "Epoch [920/3000], Loss: 1.9171\n",
      "Epoch [921/3000], Loss: 0.6684\n",
      "Epoch [922/3000], Loss: 0.4408\n",
      "Epoch [923/3000], Loss: 0.1715\n",
      "Epoch [924/3000], Loss: 0.4758\n",
      "Epoch [925/3000], Loss: 1.8017\n",
      "Epoch [926/3000], Loss: 0.7861\n",
      "Epoch [927/3000], Loss: 0.7351\n",
      "Epoch [928/3000], Loss: 0.8340\n",
      "Epoch [929/3000], Loss: 0.8056\n",
      "Epoch [930/3000], Loss: 1.0359\n",
      "Epoch [931/3000], Loss: 0.7121\n",
      "Epoch [932/3000], Loss: 0.2504\n",
      "Epoch [933/3000], Loss: 0.2897\n",
      "Epoch [934/3000], Loss: 0.2392\n",
      "Epoch [935/3000], Loss: 0.5636\n",
      "Epoch [936/3000], Loss: 0.8414\n",
      "Epoch [937/3000], Loss: 1.3200\n",
      "Epoch [938/3000], Loss: 0.7658\n",
      "Epoch [939/3000], Loss: 0.2123\n",
      "Epoch [940/3000], Loss: 1.2510\n",
      "Epoch [941/3000], Loss: 0.7717\n",
      "Epoch [942/3000], Loss: 0.9425\n",
      "Epoch [943/3000], Loss: 0.5186\n",
      "Epoch [944/3000], Loss: 2.0806\n",
      "Epoch [945/3000], Loss: 1.7145\n",
      "Epoch [946/3000], Loss: 0.5226\n",
      "Epoch [947/3000], Loss: 0.3253\n",
      "Epoch [948/3000], Loss: 0.1667\n",
      "Epoch [949/3000], Loss: 0.6661\n",
      "Epoch [950/3000], Loss: 1.0054\n",
      "Epoch [951/3000], Loss: 0.2637\n",
      "Epoch [952/3000], Loss: 1.3027\n",
      "Epoch [953/3000], Loss: 0.1437\n",
      "Epoch [954/3000], Loss: 0.4834\n",
      "Epoch [955/3000], Loss: 0.3928\n",
      "Epoch [956/3000], Loss: 0.8141\n",
      "Epoch [957/3000], Loss: 0.7016\n",
      "Epoch [958/3000], Loss: 0.4021\n",
      "Epoch [959/3000], Loss: 0.6507\n",
      "Epoch [960/3000], Loss: 0.0446\n",
      "Epoch [961/3000], Loss: 0.8830\n",
      "Epoch [962/3000], Loss: 0.2266\n",
      "Epoch [963/3000], Loss: 0.6998\n",
      "Epoch [964/3000], Loss: 0.2454\n",
      "Epoch [965/3000], Loss: 2.0511\n",
      "Epoch [966/3000], Loss: 0.1615\n",
      "Epoch [967/3000], Loss: 0.8687\n",
      "Epoch [968/3000], Loss: 0.0268\n",
      "Epoch [969/3000], Loss: 0.5329\n",
      "Epoch [970/3000], Loss: 0.0790\n",
      "Epoch [971/3000], Loss: 0.4728\n",
      "Epoch [972/3000], Loss: 0.9474\n",
      "Epoch [973/3000], Loss: 0.9000\n",
      "Epoch [974/3000], Loss: 1.0567\n",
      "Epoch [975/3000], Loss: 1.2705\n",
      "Epoch [976/3000], Loss: 0.4976\n",
      "Epoch [977/3000], Loss: 1.2725\n",
      "Epoch [978/3000], Loss: 0.3662\n",
      "Epoch [979/3000], Loss: 0.2074\n",
      "Epoch [980/3000], Loss: 1.1770\n",
      "Epoch [981/3000], Loss: 0.1744\n",
      "Epoch [982/3000], Loss: 0.5086\n",
      "Epoch [983/3000], Loss: 1.6448\n",
      "Epoch [984/3000], Loss: 1.1177\n",
      "Epoch [985/3000], Loss: 1.7668\n",
      "Epoch [986/3000], Loss: 1.8079\n",
      "Epoch [987/3000], Loss: 0.5702\n",
      "Epoch [988/3000], Loss: 0.6408\n",
      "Epoch [989/3000], Loss: 0.0549\n",
      "Epoch [990/3000], Loss: 0.1853\n",
      "Epoch [991/3000], Loss: 0.3132\n",
      "Epoch [992/3000], Loss: 0.1844\n",
      "Epoch [993/3000], Loss: 0.4022\n",
      "Epoch [994/3000], Loss: 0.1998\n",
      "Epoch [995/3000], Loss: 2.2340\n",
      "Epoch [996/3000], Loss: 0.4346\n",
      "Epoch [997/3000], Loss: 0.6995\n",
      "Epoch [998/3000], Loss: 0.3383\n",
      "Epoch [999/3000], Loss: 0.1149\n",
      "Epoch [1000/3000], Loss: 0.5197\n",
      "Epoch [1001/3000], Loss: 1.4885\n",
      "Epoch [1002/3000], Loss: 1.0877\n",
      "Epoch [1003/3000], Loss: 0.7500\n",
      "Epoch [1004/3000], Loss: 0.4020\n",
      "Epoch [1005/3000], Loss: 0.9340\n",
      "Epoch [1006/3000], Loss: 0.3743\n",
      "Epoch [1007/3000], Loss: 1.2774\n",
      "Epoch [1008/3000], Loss: 0.5430\n",
      "Epoch [1009/3000], Loss: 0.5135\n",
      "Epoch [1010/3000], Loss: 0.2291\n",
      "Epoch [1011/3000], Loss: 0.4966\n",
      "Epoch [1012/3000], Loss: 0.8675\n",
      "Epoch [1013/3000], Loss: 0.2422\n",
      "Epoch [1014/3000], Loss: 0.6466\n",
      "Epoch [1015/3000], Loss: 1.1071\n",
      "Epoch [1016/3000], Loss: 0.4675\n",
      "Epoch [1017/3000], Loss: 0.3398\n",
      "Epoch [1018/3000], Loss: 0.4014\n",
      "Epoch [1019/3000], Loss: 0.4322\n",
      "Epoch [1020/3000], Loss: 0.3461\n",
      "Epoch [1021/3000], Loss: 1.1788\n",
      "Epoch [1022/3000], Loss: 0.1110\n",
      "Epoch [1023/3000], Loss: 0.6163\n",
      "Epoch [1024/3000], Loss: 0.1177\n",
      "Epoch [1025/3000], Loss: 0.4295\n",
      "Epoch [1026/3000], Loss: 1.0852\n",
      "Epoch [1027/3000], Loss: 0.3372\n",
      "Epoch [1028/3000], Loss: 0.1194\n",
      "Epoch [1029/3000], Loss: 0.6000\n",
      "Epoch [1030/3000], Loss: 0.8169\n",
      "Epoch [1031/3000], Loss: 0.5364\n",
      "Epoch [1032/3000], Loss: 0.9713\n",
      "Epoch [1033/3000], Loss: 0.8140\n",
      "Epoch [1034/3000], Loss: 1.2956\n",
      "Epoch [1035/3000], Loss: 0.6040\n",
      "Epoch [1036/3000], Loss: 1.2034\n",
      "Epoch [1037/3000], Loss: 0.1766\n",
      "Epoch [1038/3000], Loss: 0.4290\n",
      "Epoch [1039/3000], Loss: 1.0616\n",
      "Epoch [1040/3000], Loss: 0.3899\n",
      "Epoch [1041/3000], Loss: 0.7279\n",
      "Epoch [1042/3000], Loss: 0.5556\n",
      "Epoch [1043/3000], Loss: 0.0435\n",
      "Epoch [1044/3000], Loss: 0.3221\n",
      "Epoch [1045/3000], Loss: 0.5357\n",
      "Epoch [1046/3000], Loss: 0.2346\n",
      "Epoch [1047/3000], Loss: 0.2177\n",
      "Epoch [1048/3000], Loss: 1.7326\n",
      "Epoch [1049/3000], Loss: 1.3861\n",
      "Epoch [1050/3000], Loss: 0.9085\n",
      "Epoch [1051/3000], Loss: 0.9531\n",
      "Epoch [1052/3000], Loss: 0.4854\n",
      "Epoch [1053/3000], Loss: 0.9291\n",
      "Epoch [1054/3000], Loss: 0.8580\n",
      "Epoch [1055/3000], Loss: 0.1520\n",
      "Epoch [1056/3000], Loss: 0.8055\n",
      "Epoch [1057/3000], Loss: 0.7646\n",
      "Epoch [1058/3000], Loss: 0.5752\n",
      "Epoch [1059/3000], Loss: 0.0352\n",
      "Epoch [1060/3000], Loss: 1.0062\n",
      "Epoch [1061/3000], Loss: 0.9376\n",
      "Epoch [1062/3000], Loss: 0.7753\n",
      "Epoch [1063/3000], Loss: 0.0168\n",
      "Epoch [1064/3000], Loss: 1.0062\n",
      "Epoch [1065/3000], Loss: 0.7528\n",
      "Epoch [1066/3000], Loss: 0.0550\n",
      "Epoch [1067/3000], Loss: 0.9369\n",
      "Epoch [1068/3000], Loss: 1.3545\n",
      "Epoch [1069/3000], Loss: 0.0627\n",
      "Epoch [1070/3000], Loss: 0.2145\n",
      "Epoch [1071/3000], Loss: 0.0374\n",
      "Epoch [1072/3000], Loss: 1.1445\n",
      "Epoch [1073/3000], Loss: 0.4868\n",
      "Epoch [1074/3000], Loss: 0.8680\n",
      "Epoch [1075/3000], Loss: 0.3599\n",
      "Epoch [1076/3000], Loss: 1.0242\n",
      "Epoch [1077/3000], Loss: 0.5766\n",
      "Epoch [1078/3000], Loss: 1.1096\n",
      "Epoch [1079/3000], Loss: 0.2704\n",
      "Epoch [1080/3000], Loss: 0.8798\n",
      "Epoch [1081/3000], Loss: 0.4191\n",
      "Epoch [1082/3000], Loss: 2.1213\n",
      "Epoch [1083/3000], Loss: 0.6698\n",
      "Epoch [1084/3000], Loss: 0.6396\n",
      "Epoch [1085/3000], Loss: 1.6606\n",
      "Epoch [1086/3000], Loss: 1.1663\n",
      "Epoch [1087/3000], Loss: 1.7566\n",
      "Epoch [1088/3000], Loss: 0.7298\n",
      "Epoch [1089/3000], Loss: 0.8142\n",
      "Epoch [1090/3000], Loss: 0.3679\n",
      "Epoch [1091/3000], Loss: 1.9802\n",
      "Epoch [1092/3000], Loss: 0.4917\n",
      "Epoch [1093/3000], Loss: 0.1668\n",
      "Epoch [1094/3000], Loss: 0.6203\n",
      "Epoch [1095/3000], Loss: 0.5704\n",
      "Epoch [1096/3000], Loss: 0.3930\n",
      "Epoch [1097/3000], Loss: 0.5048\n",
      "Epoch [1098/3000], Loss: 0.3512\n",
      "Epoch [1099/3000], Loss: 1.7706\n",
      "Epoch [1100/3000], Loss: 0.4314\n",
      "Epoch [1101/3000], Loss: 0.6879\n",
      "Epoch [1102/3000], Loss: 0.2207\n",
      "Epoch [1103/3000], Loss: 1.3929\n",
      "Epoch [1104/3000], Loss: 2.1876\n",
      "Epoch [1105/3000], Loss: 0.9610\n",
      "Epoch [1106/3000], Loss: 0.3252\n",
      "Epoch [1107/3000], Loss: 0.6298\n",
      "Epoch [1108/3000], Loss: 0.0304\n",
      "Epoch [1109/3000], Loss: 0.4031\n",
      "Epoch [1110/3000], Loss: 0.3362\n",
      "Epoch [1111/3000], Loss: 0.5287\n",
      "Epoch [1112/3000], Loss: 0.4919\n",
      "Epoch [1113/3000], Loss: 0.3259\n",
      "Epoch [1114/3000], Loss: 0.6422\n",
      "Epoch [1115/3000], Loss: 0.2456\n",
      "Epoch [1116/3000], Loss: 0.1491\n",
      "Epoch [1117/3000], Loss: 1.7788\n",
      "Epoch [1118/3000], Loss: 0.0996\n",
      "Epoch [1119/3000], Loss: 0.3470\n",
      "Epoch [1120/3000], Loss: 0.7146\n",
      "Epoch [1121/3000], Loss: 0.4978\n",
      "Epoch [1122/3000], Loss: 0.3635\n",
      "Epoch [1123/3000], Loss: 0.5046\n",
      "Epoch [1124/3000], Loss: 0.4818\n",
      "Epoch [1125/3000], Loss: 1.0385\n",
      "Epoch [1126/3000], Loss: 0.4470\n",
      "Epoch [1127/3000], Loss: 0.5929\n",
      "Epoch [1128/3000], Loss: 0.4290\n",
      "Epoch [1129/3000], Loss: 0.3365\n",
      "Epoch [1130/3000], Loss: 2.2443\n",
      "Epoch [1131/3000], Loss: 0.7583\n",
      "Epoch [1132/3000], Loss: 0.5676\n",
      "Epoch [1133/3000], Loss: 0.2837\n",
      "Epoch [1134/3000], Loss: 0.3853\n",
      "Epoch [1135/3000], Loss: 0.0691\n",
      "Epoch [1136/3000], Loss: 0.8894\n",
      "Epoch [1137/3000], Loss: 1.6484\n",
      "Epoch [1138/3000], Loss: 1.1647\n",
      "Epoch [1139/3000], Loss: 1.0899\n",
      "Epoch [1140/3000], Loss: 0.4933\n",
      "Epoch [1141/3000], Loss: 0.2684\n",
      "Epoch [1142/3000], Loss: 0.3647\n",
      "Epoch [1143/3000], Loss: 0.7185\n",
      "Epoch [1144/3000], Loss: 2.0561\n",
      "Epoch [1145/3000], Loss: 0.2565\n",
      "Epoch [1146/3000], Loss: 0.1576\n",
      "Epoch [1147/3000], Loss: 2.0222\n",
      "Epoch [1148/3000], Loss: 0.2897\n",
      "Epoch [1149/3000], Loss: 0.0199\n",
      "Epoch [1150/3000], Loss: 0.4101\n",
      "Epoch [1151/3000], Loss: 0.7931\n",
      "Epoch [1152/3000], Loss: 1.9534\n",
      "Epoch [1153/3000], Loss: 1.6157\n",
      "Epoch [1154/3000], Loss: 0.4350\n",
      "Epoch [1155/3000], Loss: 0.9112\n",
      "Epoch [1156/3000], Loss: 0.9060\n",
      "Epoch [1157/3000], Loss: 0.5561\n",
      "Epoch [1158/3000], Loss: 0.0513\n",
      "Epoch [1159/3000], Loss: 0.3793\n",
      "Epoch [1160/3000], Loss: 0.6638\n",
      "Epoch [1161/3000], Loss: 0.6297\n",
      "Epoch [1162/3000], Loss: 1.0610\n",
      "Epoch [1163/3000], Loss: 0.2413\n",
      "Epoch [1164/3000], Loss: 0.5938\n",
      "Epoch [1165/3000], Loss: 1.0366\n",
      "Epoch [1166/3000], Loss: 1.5594\n",
      "Epoch [1167/3000], Loss: 1.2624\n",
      "Epoch [1168/3000], Loss: 0.5417\n",
      "Epoch [1169/3000], Loss: 0.1784\n",
      "Epoch [1170/3000], Loss: 0.3251\n",
      "Epoch [1171/3000], Loss: 1.1915\n",
      "Epoch [1172/3000], Loss: 0.4695\n",
      "Epoch [1173/3000], Loss: 0.6920\n",
      "Epoch [1174/3000], Loss: 0.4092\n",
      "Epoch [1175/3000], Loss: 0.3533\n",
      "Epoch [1176/3000], Loss: 0.2986\n",
      "Epoch [1177/3000], Loss: 0.1908\n",
      "Epoch [1178/3000], Loss: 0.2923\n",
      "Epoch [1179/3000], Loss: 2.0475\n",
      "Epoch [1180/3000], Loss: 0.8853\n",
      "Epoch [1181/3000], Loss: 0.3805\n",
      "Epoch [1182/3000], Loss: 0.8616\n",
      "Epoch [1183/3000], Loss: 0.0968\n",
      "Epoch [1184/3000], Loss: 0.3301\n",
      "Epoch [1185/3000], Loss: 0.3540\n",
      "Epoch [1186/3000], Loss: 0.2599\n",
      "Epoch [1187/3000], Loss: 0.1616\n",
      "Epoch [1188/3000], Loss: 0.2825\n",
      "Epoch [1189/3000], Loss: 1.3749\n",
      "Epoch [1190/3000], Loss: 0.1589\n",
      "Epoch [1191/3000], Loss: 0.5418\n",
      "Epoch [1192/3000], Loss: 0.1313\n",
      "Epoch [1193/3000], Loss: 0.2644\n",
      "Epoch [1194/3000], Loss: 0.0964\n",
      "Epoch [1195/3000], Loss: 0.1883\n",
      "Epoch [1196/3000], Loss: 0.2470\n",
      "Epoch [1197/3000], Loss: 0.9258\n",
      "Epoch [1198/3000], Loss: 0.1070\n",
      "Epoch [1199/3000], Loss: 0.2692\n",
      "Epoch [1200/3000], Loss: 2.3585\n",
      "Epoch [1201/3000], Loss: 0.2601\n",
      "Epoch [1202/3000], Loss: 1.3843\n",
      "Epoch [1203/3000], Loss: 1.4107\n",
      "Epoch [1204/3000], Loss: 1.4114\n",
      "Epoch [1205/3000], Loss: 1.4471\n",
      "Epoch [1206/3000], Loss: 0.3641\n",
      "Epoch [1207/3000], Loss: 0.7516\n",
      "Epoch [1208/3000], Loss: 0.8223\n",
      "Epoch [1209/3000], Loss: 0.5913\n",
      "Epoch [1210/3000], Loss: 0.2465\n",
      "Epoch [1211/3000], Loss: 2.3524\n",
      "Epoch [1212/3000], Loss: 2.0126\n",
      "Epoch [1213/3000], Loss: 1.3224\n",
      "Epoch [1214/3000], Loss: 0.0536\n",
      "Epoch [1215/3000], Loss: 0.7291\n",
      "Epoch [1216/3000], Loss: 0.6317\n",
      "Epoch [1217/3000], Loss: 2.5538\n",
      "Epoch [1218/3000], Loss: 0.3017\n",
      "Epoch [1219/3000], Loss: 0.6457\n",
      "Epoch [1220/3000], Loss: 0.2687\n",
      "Epoch [1221/3000], Loss: 1.0744\n",
      "Epoch [1222/3000], Loss: 0.8821\n",
      "Epoch [1223/3000], Loss: 0.1343\n",
      "Epoch [1224/3000], Loss: 0.0078\n",
      "Epoch [1225/3000], Loss: 0.9420\n",
      "Epoch [1226/3000], Loss: 0.5584\n",
      "Epoch [1227/3000], Loss: 0.5773\n",
      "Epoch [1228/3000], Loss: 0.8984\n",
      "Epoch [1229/3000], Loss: 0.8184\n",
      "Epoch [1230/3000], Loss: 2.9030\n",
      "Epoch [1231/3000], Loss: 0.5335\n",
      "Epoch [1232/3000], Loss: 0.5729\n",
      "Epoch [1233/3000], Loss: 0.4547\n",
      "Epoch [1234/3000], Loss: 0.2173\n",
      "Epoch [1235/3000], Loss: 0.8292\n",
      "Epoch [1236/3000], Loss: 0.5993\n",
      "Epoch [1237/3000], Loss: 0.0547\n",
      "Epoch [1238/3000], Loss: 0.5279\n",
      "Epoch [1239/3000], Loss: 0.3623\n",
      "Epoch [1240/3000], Loss: 2.0096\n",
      "Epoch [1241/3000], Loss: 0.0837\n",
      "Epoch [1242/3000], Loss: 0.0656\n",
      "Epoch [1243/3000], Loss: 0.9072\n",
      "Epoch [1244/3000], Loss: 1.1353\n",
      "Epoch [1245/3000], Loss: 0.1632\n",
      "Epoch [1246/3000], Loss: 2.4398\n",
      "Epoch [1247/3000], Loss: 0.7705\n",
      "Epoch [1248/3000], Loss: 1.7880\n",
      "Epoch [1249/3000], Loss: 0.7123\n",
      "Epoch [1250/3000], Loss: 1.2442\n",
      "Epoch [1251/3000], Loss: 0.1778\n",
      "Epoch [1252/3000], Loss: 0.7151\n",
      "Epoch [1253/3000], Loss: 1.0626\n",
      "Epoch [1254/3000], Loss: 0.3089\n",
      "Epoch [1255/3000], Loss: 0.0115\n",
      "Epoch [1256/3000], Loss: 0.5910\n",
      "Epoch [1257/3000], Loss: 0.3079\n",
      "Epoch [1258/3000], Loss: 0.6809\n",
      "Epoch [1259/3000], Loss: 1.5188\n",
      "Epoch [1260/3000], Loss: 0.0774\n",
      "Epoch [1261/3000], Loss: 0.1067\n",
      "Epoch [1262/3000], Loss: 0.1610\n",
      "Epoch [1263/3000], Loss: 0.8264\n",
      "Epoch [1264/3000], Loss: 0.7333\n",
      "Epoch [1265/3000], Loss: 0.2482\n",
      "Epoch [1266/3000], Loss: 1.3800\n",
      "Epoch [1267/3000], Loss: 1.0875\n",
      "Epoch [1268/3000], Loss: 0.2291\n",
      "Epoch [1269/3000], Loss: 0.5512\n",
      "Epoch [1270/3000], Loss: 1.1810\n",
      "Epoch [1271/3000], Loss: 0.2552\n",
      "Epoch [1272/3000], Loss: 2.3476\n",
      "Epoch [1273/3000], Loss: 0.5077\n",
      "Epoch [1274/3000], Loss: 0.1713\n",
      "Epoch [1275/3000], Loss: 0.2088\n",
      "Epoch [1276/3000], Loss: 0.2736\n",
      "Epoch [1277/3000], Loss: 0.2400\n",
      "Epoch [1278/3000], Loss: 0.6624\n",
      "Epoch [1279/3000], Loss: 0.7687\n",
      "Epoch [1280/3000], Loss: 1.1513\n",
      "Epoch [1281/3000], Loss: 0.8418\n",
      "Epoch [1282/3000], Loss: 0.1992\n",
      "Epoch [1283/3000], Loss: 0.4355\n",
      "Epoch [1284/3000], Loss: 0.1928\n",
      "Epoch [1285/3000], Loss: 0.4835\n",
      "Epoch [1286/3000], Loss: 0.4111\n",
      "Epoch [1287/3000], Loss: 1.0909\n",
      "Epoch [1288/3000], Loss: 0.2757\n",
      "Epoch [1289/3000], Loss: 0.6705\n",
      "Epoch [1290/3000], Loss: 1.6422\n",
      "Epoch [1291/3000], Loss: 0.3681\n",
      "Epoch [1292/3000], Loss: 0.1377\n",
      "Epoch [1293/3000], Loss: 3.3794\n",
      "Epoch [1294/3000], Loss: 0.0754\n",
      "Epoch [1295/3000], Loss: 0.2457\n",
      "Epoch [1296/3000], Loss: 0.4504\n",
      "Epoch [1297/3000], Loss: 0.3238\n",
      "Epoch [1298/3000], Loss: 0.8446\n",
      "Epoch [1299/3000], Loss: 0.2286\n",
      "Epoch [1300/3000], Loss: 1.3956\n",
      "Epoch [1301/3000], Loss: 2.3752\n",
      "Epoch [1302/3000], Loss: 0.5287\n",
      "Epoch [1303/3000], Loss: 0.3593\n",
      "Epoch [1304/3000], Loss: 0.8095\n",
      "Epoch [1305/3000], Loss: 0.2297\n",
      "Epoch [1306/3000], Loss: 0.6537\n",
      "Epoch [1307/3000], Loss: 0.3478\n",
      "Epoch [1308/3000], Loss: 0.0272\n",
      "Epoch [1309/3000], Loss: 0.4469\n",
      "Epoch [1310/3000], Loss: 0.1670\n",
      "Epoch [1311/3000], Loss: 2.0364\n",
      "Epoch [1312/3000], Loss: 0.7684\n",
      "Epoch [1313/3000], Loss: 0.6807\n",
      "Epoch [1314/3000], Loss: 0.3111\n",
      "Epoch [1315/3000], Loss: 0.1848\n",
      "Epoch [1316/3000], Loss: 1.0454\n",
      "Epoch [1317/3000], Loss: 0.0931\n",
      "Epoch [1318/3000], Loss: 0.2886\n",
      "Epoch [1319/3000], Loss: 0.9765\n",
      "Epoch [1320/3000], Loss: 1.0891\n",
      "Epoch [1321/3000], Loss: 0.8686\n",
      "Epoch [1322/3000], Loss: 0.2635\n",
      "Epoch [1323/3000], Loss: 0.8688\n",
      "Epoch [1324/3000], Loss: 0.5280\n",
      "Epoch [1325/3000], Loss: 1.3646\n",
      "Epoch [1326/3000], Loss: 0.2084\n",
      "Epoch [1327/3000], Loss: 0.5247\n",
      "Epoch [1328/3000], Loss: 0.9151\n",
      "Epoch [1329/3000], Loss: 0.6525\n",
      "Epoch [1330/3000], Loss: 0.8246\n",
      "Epoch [1331/3000], Loss: 2.0349\n",
      "Epoch [1332/3000], Loss: 0.6072\n",
      "Epoch [1333/3000], Loss: 2.1712\n",
      "Epoch [1334/3000], Loss: 0.2303\n",
      "Epoch [1335/3000], Loss: 0.2239\n",
      "Epoch [1336/3000], Loss: 0.4006\n",
      "Epoch [1337/3000], Loss: 0.2063\n",
      "Epoch [1338/3000], Loss: 0.8765\n",
      "Epoch [1339/3000], Loss: 0.5195\n",
      "Epoch [1340/3000], Loss: 0.7487\n",
      "Epoch [1341/3000], Loss: 1.8740\n",
      "Epoch [1342/3000], Loss: 2.3960\n",
      "Epoch [1343/3000], Loss: 0.6158\n",
      "Epoch [1344/3000], Loss: 0.6570\n",
      "Epoch [1345/3000], Loss: 0.9856\n",
      "Epoch [1346/3000], Loss: 0.5107\n",
      "Epoch [1347/3000], Loss: 0.8841\n",
      "Epoch [1348/3000], Loss: 0.4752\n",
      "Epoch [1349/3000], Loss: 0.4919\n",
      "Epoch [1350/3000], Loss: 0.6464\n",
      "Epoch [1351/3000], Loss: 0.8338\n",
      "Epoch [1352/3000], Loss: 1.9963\n",
      "Epoch [1353/3000], Loss: 0.4358\n",
      "Epoch [1354/3000], Loss: 0.3714\n",
      "Epoch [1355/3000], Loss: 0.5577\n",
      "Epoch [1356/3000], Loss: 0.9878\n",
      "Epoch [1357/3000], Loss: 1.4395\n",
      "Epoch [1358/3000], Loss: 2.0066\n",
      "Epoch [1359/3000], Loss: 2.0284\n",
      "Epoch [1360/3000], Loss: 1.1201\n",
      "Epoch [1361/3000], Loss: 0.5305\n",
      "Epoch [1362/3000], Loss: 0.4591\n",
      "Epoch [1363/3000], Loss: 0.0655\n",
      "Epoch [1364/3000], Loss: 0.2240\n",
      "Epoch [1365/3000], Loss: 0.1851\n",
      "Epoch [1366/3000], Loss: 0.8080\n",
      "Epoch [1367/3000], Loss: 0.9838\n",
      "Epoch [1368/3000], Loss: 0.1031\n",
      "Epoch [1369/3000], Loss: 0.3046\n",
      "Epoch [1370/3000], Loss: 0.7179\n",
      "Epoch [1371/3000], Loss: 1.5034\n",
      "Epoch [1372/3000], Loss: 0.4000\n",
      "Epoch [1373/3000], Loss: 0.4749\n",
      "Epoch [1374/3000], Loss: 1.4241\n",
      "Epoch [1375/3000], Loss: 0.8909\n",
      "Epoch [1376/3000], Loss: 0.5176\n",
      "Epoch [1377/3000], Loss: 0.4063\n",
      "Epoch [1378/3000], Loss: 0.3868\n",
      "Epoch [1379/3000], Loss: 0.2368\n",
      "Epoch [1380/3000], Loss: 0.3032\n",
      "Epoch [1381/3000], Loss: 0.1606\n",
      "Epoch [1382/3000], Loss: 0.3114\n",
      "Epoch [1383/3000], Loss: 0.1685\n",
      "Epoch [1384/3000], Loss: 0.5542\n",
      "Epoch [1385/3000], Loss: 1.5550\n",
      "Epoch [1386/3000], Loss: 0.2653\n",
      "Epoch [1387/3000], Loss: 0.5151\n",
      "Epoch [1388/3000], Loss: 0.7032\n",
      "Epoch [1389/3000], Loss: 0.4807\n",
      "Epoch [1390/3000], Loss: 1.1464\n",
      "Epoch [1391/3000], Loss: 0.7332\n",
      "Epoch [1392/3000], Loss: 0.1390\n",
      "Epoch [1393/3000], Loss: 0.9934\n",
      "Epoch [1394/3000], Loss: 0.2954\n",
      "Epoch [1395/3000], Loss: 0.7018\n",
      "Epoch [1396/3000], Loss: 0.3610\n",
      "Epoch [1397/3000], Loss: 0.3164\n",
      "Epoch [1398/3000], Loss: 0.9060\n",
      "Epoch [1399/3000], Loss: 1.5363\n",
      "Epoch [1400/3000], Loss: 0.8677\n",
      "Epoch [1401/3000], Loss: 0.8481\n",
      "Epoch [1402/3000], Loss: 0.6168\n",
      "Epoch [1403/3000], Loss: 0.2420\n",
      "Epoch [1404/3000], Loss: 0.0127\n",
      "Epoch [1405/3000], Loss: 1.6185\n",
      "Epoch [1406/3000], Loss: 0.1221\n",
      "Epoch [1407/3000], Loss: 0.0419\n",
      "Epoch [1408/3000], Loss: 0.3257\n",
      "Epoch [1409/3000], Loss: 0.6688\n",
      "Epoch [1410/3000], Loss: 0.8302\n",
      "Epoch [1411/3000], Loss: 0.5172\n",
      "Epoch [1412/3000], Loss: 1.1998\n",
      "Epoch [1413/3000], Loss: 0.9822\n",
      "Epoch [1414/3000], Loss: 1.0899\n",
      "Epoch [1415/3000], Loss: 0.3175\n",
      "Epoch [1416/3000], Loss: 1.0610\n",
      "Epoch [1417/3000], Loss: 0.2420\n",
      "Epoch [1418/3000], Loss: 1.0289\n",
      "Epoch [1419/3000], Loss: 2.3774\n",
      "Epoch [1420/3000], Loss: 0.2604\n",
      "Epoch [1421/3000], Loss: 0.1302\n",
      "Epoch [1422/3000], Loss: 0.4018\n",
      "Epoch [1423/3000], Loss: 0.0303\n",
      "Epoch [1424/3000], Loss: 1.0318\n",
      "Epoch [1425/3000], Loss: 0.3736\n",
      "Epoch [1426/3000], Loss: 0.4310\n",
      "Epoch [1427/3000], Loss: 0.4883\n",
      "Epoch [1428/3000], Loss: 0.2440\n",
      "Epoch [1429/3000], Loss: 0.2777\n",
      "Epoch [1430/3000], Loss: 0.6298\n",
      "Epoch [1431/3000], Loss: 1.0592\n",
      "Epoch [1432/3000], Loss: 1.1885\n",
      "Epoch [1433/3000], Loss: 1.6801\n",
      "Epoch [1434/3000], Loss: 0.0664\n",
      "Epoch [1435/3000], Loss: 0.3840\n",
      "Epoch [1436/3000], Loss: 0.9210\n",
      "Epoch [1437/3000], Loss: 0.1964\n",
      "Epoch [1438/3000], Loss: 0.1172\n",
      "Epoch [1439/3000], Loss: 1.6995\n",
      "Epoch [1440/3000], Loss: 0.4535\n",
      "Epoch [1441/3000], Loss: 0.4915\n",
      "Epoch [1442/3000], Loss: 1.5457\n",
      "Epoch [1443/3000], Loss: 0.8588\n",
      "Epoch [1444/3000], Loss: 0.4960\n",
      "Epoch [1445/3000], Loss: 0.9124\n",
      "Epoch [1446/3000], Loss: 0.6210\n",
      "Epoch [1447/3000], Loss: 0.4839\n",
      "Epoch [1448/3000], Loss: 0.5033\n",
      "Epoch [1449/3000], Loss: 0.0224\n",
      "Epoch [1450/3000], Loss: 0.5703\n",
      "Epoch [1451/3000], Loss: 1.7889\n",
      "Epoch [1452/3000], Loss: 0.8808\n",
      "Epoch [1453/3000], Loss: 0.3023\n",
      "Epoch [1454/3000], Loss: 0.3553\n",
      "Epoch [1455/3000], Loss: 0.3921\n",
      "Epoch [1456/3000], Loss: 0.1080\n",
      "Epoch [1457/3000], Loss: 0.1370\n",
      "Epoch [1458/3000], Loss: 1.3930\n",
      "Epoch [1459/3000], Loss: 0.1609\n",
      "Epoch [1460/3000], Loss: 0.1380\n",
      "Epoch [1461/3000], Loss: 0.2443\n",
      "Epoch [1462/3000], Loss: 0.4889\n",
      "Epoch [1463/3000], Loss: 0.0563\n",
      "Epoch [1464/3000], Loss: 0.7602\n",
      "Epoch [1465/3000], Loss: 0.1681\n",
      "Epoch [1466/3000], Loss: 2.5665\n",
      "Epoch [1467/3000], Loss: 1.6568\n",
      "Epoch [1468/3000], Loss: 2.0522\n",
      "Epoch [1469/3000], Loss: 0.0640\n",
      "Epoch [1470/3000], Loss: 0.8418\n",
      "Epoch [1471/3000], Loss: 0.8559\n",
      "Epoch [1472/3000], Loss: 0.4281\n",
      "Epoch [1473/3000], Loss: 1.1276\n",
      "Epoch [1474/3000], Loss: 0.5308\n",
      "Epoch [1475/3000], Loss: 0.3648\n",
      "Epoch [1476/3000], Loss: 0.1566\n",
      "Epoch [1477/3000], Loss: 0.4509\n",
      "Epoch [1478/3000], Loss: 0.4000\n",
      "Epoch [1479/3000], Loss: 0.6952\n",
      "Epoch [1480/3000], Loss: 0.0914\n",
      "Epoch [1481/3000], Loss: 0.2163\n",
      "Epoch [1482/3000], Loss: 0.2009\n",
      "Epoch [1483/3000], Loss: 1.6304\n",
      "Epoch [1484/3000], Loss: 1.7238\n",
      "Epoch [1485/3000], Loss: 1.0821\n",
      "Epoch [1486/3000], Loss: 0.3586\n",
      "Epoch [1487/3000], Loss: 0.6430\n",
      "Epoch [1488/3000], Loss: 0.1061\n",
      "Epoch [1489/3000], Loss: 0.4143\n",
      "Epoch [1490/3000], Loss: 0.8880\n",
      "Epoch [1491/3000], Loss: 0.4780\n",
      "Epoch [1492/3000], Loss: 0.4233\n",
      "Epoch [1493/3000], Loss: 0.0538\n",
      "Epoch [1494/3000], Loss: 0.3633\n",
      "Epoch [1495/3000], Loss: 0.6260\n",
      "Epoch [1496/3000], Loss: 0.3606\n",
      "Epoch [1497/3000], Loss: 0.6818\n",
      "Epoch [1498/3000], Loss: 0.5335\n",
      "Epoch [1499/3000], Loss: 0.8544\n",
      "Epoch [1500/3000], Loss: 0.6517\n",
      "Epoch [1501/3000], Loss: 0.3107\n",
      "Epoch [1502/3000], Loss: 0.3848\n",
      "Epoch [1503/3000], Loss: 0.3101\n",
      "Epoch [1504/3000], Loss: 1.0365\n",
      "Epoch [1505/3000], Loss: 0.3413\n",
      "Epoch [1506/3000], Loss: 0.2866\n",
      "Epoch [1507/3000], Loss: 1.1262\n",
      "Epoch [1508/3000], Loss: 0.1059\n",
      "Epoch [1509/3000], Loss: 0.1199\n",
      "Epoch [1510/3000], Loss: 0.6433\n",
      "Epoch [1511/3000], Loss: 1.1466\n",
      "Epoch [1512/3000], Loss: 0.6272\n",
      "Epoch [1513/3000], Loss: 1.6528\n",
      "Epoch [1514/3000], Loss: 0.0576\n",
      "Epoch [1515/3000], Loss: 0.8630\n",
      "Epoch [1516/3000], Loss: 1.7917\n",
      "Epoch [1517/3000], Loss: 0.7052\n",
      "Epoch [1518/3000], Loss: 0.4286\n",
      "Epoch [1519/3000], Loss: 0.1901\n",
      "Epoch [1520/3000], Loss: 0.1344\n",
      "Epoch [1521/3000], Loss: 1.4568\n",
      "Epoch [1522/3000], Loss: 0.1298\n",
      "Epoch [1523/3000], Loss: 0.8916\n",
      "Epoch [1524/3000], Loss: 0.3949\n",
      "Epoch [1525/3000], Loss: 2.3933\n",
      "Epoch [1526/3000], Loss: 0.1236\n",
      "Epoch [1527/3000], Loss: 0.1287\n",
      "Epoch [1528/3000], Loss: 0.3359\n",
      "Epoch [1529/3000], Loss: 0.9599\n",
      "Epoch [1530/3000], Loss: 0.3901\n",
      "Epoch [1531/3000], Loss: 0.7325\n",
      "Epoch [1532/3000], Loss: 0.6556\n",
      "Epoch [1533/3000], Loss: 0.3569\n",
      "Epoch [1534/3000], Loss: 1.5031\n",
      "Epoch [1535/3000], Loss: 0.1072\n",
      "Epoch [1536/3000], Loss: 0.3847\n",
      "Epoch [1537/3000], Loss: 0.4460\n",
      "Epoch [1538/3000], Loss: 0.5117\n",
      "Epoch [1539/3000], Loss: 0.6044\n",
      "Epoch [1540/3000], Loss: 0.8109\n",
      "Epoch [1541/3000], Loss: 0.3236\n",
      "Epoch [1542/3000], Loss: 1.2759\n",
      "Epoch [1543/3000], Loss: 0.3686\n",
      "Epoch [1544/3000], Loss: 0.6351\n",
      "Epoch [1545/3000], Loss: 0.5188\n",
      "Epoch [1546/3000], Loss: 1.2400\n",
      "Epoch [1547/3000], Loss: 0.3455\n",
      "Epoch [1548/3000], Loss: 0.2196\n",
      "Epoch [1549/3000], Loss: 0.4841\n",
      "Epoch [1550/3000], Loss: 0.4961\n",
      "Epoch [1551/3000], Loss: 0.4355\n",
      "Epoch [1552/3000], Loss: 1.3453\n",
      "Epoch [1553/3000], Loss: 1.0908\n",
      "Epoch [1554/3000], Loss: 1.5367\n",
      "Epoch [1555/3000], Loss: 2.0772\n",
      "Epoch [1556/3000], Loss: 0.3749\n",
      "Epoch [1557/3000], Loss: 0.2215\n",
      "Epoch [1558/3000], Loss: 0.6464\n",
      "Epoch [1559/3000], Loss: 0.9024\n",
      "Epoch [1560/3000], Loss: 0.7185\n",
      "Epoch [1561/3000], Loss: 0.2997\n",
      "Epoch [1562/3000], Loss: 0.3915\n",
      "Epoch [1563/3000], Loss: 0.8626\n",
      "Epoch [1564/3000], Loss: 0.2877\n",
      "Epoch [1565/3000], Loss: 0.4828\n",
      "Epoch [1566/3000], Loss: 1.6179\n",
      "Epoch [1567/3000], Loss: 0.2094\n",
      "Epoch [1568/3000], Loss: 0.5225\n",
      "Epoch [1569/3000], Loss: 0.8538\n",
      "Epoch [1570/3000], Loss: 0.2793\n",
      "Epoch [1571/3000], Loss: 0.7719\n",
      "Epoch [1572/3000], Loss: 0.0315\n",
      "Epoch [1573/3000], Loss: 0.1898\n",
      "Epoch [1574/3000], Loss: 0.4578\n",
      "Epoch [1575/3000], Loss: 0.2524\n",
      "Epoch [1576/3000], Loss: 1.5253\n",
      "Epoch [1577/3000], Loss: 0.2581\n",
      "Epoch [1578/3000], Loss: 0.6776\n",
      "Epoch [1579/3000], Loss: 1.3689\n",
      "Epoch [1580/3000], Loss: 0.2790\n",
      "Epoch [1581/3000], Loss: 0.3213\n",
      "Epoch [1582/3000], Loss: 2.3366\n",
      "Epoch [1583/3000], Loss: 0.3226\n",
      "Epoch [1584/3000], Loss: 2.4478\n",
      "Epoch [1585/3000], Loss: 0.7602\n",
      "Epoch [1586/3000], Loss: 1.0457\n",
      "Epoch [1587/3000], Loss: 0.1299\n",
      "Epoch [1588/3000], Loss: 0.8837\n",
      "Epoch [1589/3000], Loss: 0.7850\n",
      "Epoch [1590/3000], Loss: 0.2284\n",
      "Epoch [1591/3000], Loss: 0.9557\n",
      "Epoch [1592/3000], Loss: 1.1620\n",
      "Epoch [1593/3000], Loss: 0.2153\n",
      "Epoch [1594/3000], Loss: 1.3005\n",
      "Epoch [1595/3000], Loss: 0.7318\n",
      "Epoch [1596/3000], Loss: 0.4295\n",
      "Epoch [1597/3000], Loss: 0.2602\n",
      "Epoch [1598/3000], Loss: 0.1317\n",
      "Epoch [1599/3000], Loss: 0.6167\n",
      "Epoch [1600/3000], Loss: 0.0769\n",
      "Epoch [1601/3000], Loss: 0.2262\n",
      "Epoch [1602/3000], Loss: 1.7775\n",
      "Epoch [1603/3000], Loss: 0.0965\n",
      "Epoch [1604/3000], Loss: 0.4322\n",
      "Epoch [1605/3000], Loss: 0.6154\n",
      "Epoch [1606/3000], Loss: 0.3205\n",
      "Epoch [1607/3000], Loss: 0.0800\n",
      "Epoch [1608/3000], Loss: 0.5265\n",
      "Epoch [1609/3000], Loss: 0.9319\n",
      "Epoch [1610/3000], Loss: 0.8207\n",
      "Epoch [1611/3000], Loss: 0.2859\n",
      "Epoch [1612/3000], Loss: 0.4911\n",
      "Epoch [1613/3000], Loss: 0.1821\n",
      "Epoch [1614/3000], Loss: 0.7662\n",
      "Epoch [1615/3000], Loss: 0.4503\n",
      "Epoch [1616/3000], Loss: 0.7089\n",
      "Epoch [1617/3000], Loss: 0.3167\n",
      "Epoch [1618/3000], Loss: 0.7523\n",
      "Epoch [1619/3000], Loss: 0.2413\n",
      "Epoch [1620/3000], Loss: 1.0317\n",
      "Epoch [1621/3000], Loss: 0.7524\n",
      "Epoch [1622/3000], Loss: 0.5296\n",
      "Epoch [1623/3000], Loss: 0.4107\n",
      "Epoch [1624/3000], Loss: 0.0795\n",
      "Epoch [1625/3000], Loss: 0.5066\n",
      "Epoch [1626/3000], Loss: 0.1167\n",
      "Epoch [1627/3000], Loss: 0.0503\n",
      "Epoch [1628/3000], Loss: 1.1319\n",
      "Epoch [1629/3000], Loss: 0.5164\n",
      "Epoch [1630/3000], Loss: 0.2687\n",
      "Epoch [1631/3000], Loss: 0.8214\n",
      "Epoch [1632/3000], Loss: 0.3724\n",
      "Epoch [1633/3000], Loss: 0.6006\n",
      "Epoch [1634/3000], Loss: 0.6203\n",
      "Epoch [1635/3000], Loss: 0.0373\n",
      "Epoch [1636/3000], Loss: 0.7014\n",
      "Epoch [1637/3000], Loss: 0.0341\n",
      "Epoch [1638/3000], Loss: 1.2979\n",
      "Epoch [1639/3000], Loss: 0.1596\n",
      "Epoch [1640/3000], Loss: 1.0493\n",
      "Epoch [1641/3000], Loss: 1.2863\n",
      "Epoch [1642/3000], Loss: 1.0816\n",
      "Epoch [1643/3000], Loss: 0.9563\n",
      "Epoch [1644/3000], Loss: 0.3568\n",
      "Epoch [1645/3000], Loss: 0.7645\n",
      "Epoch [1646/3000], Loss: 0.6872\n",
      "Epoch [1647/3000], Loss: 2.1059\n",
      "Epoch [1648/3000], Loss: 0.8415\n",
      "Epoch [1649/3000], Loss: 0.0731\n",
      "Epoch [1650/3000], Loss: 1.0043\n",
      "Epoch [1651/3000], Loss: 0.7517\n",
      "Epoch [1652/3000], Loss: 1.8448\n",
      "Epoch [1653/3000], Loss: 0.2950\n",
      "Epoch [1654/3000], Loss: 0.6358\n",
      "Epoch [1655/3000], Loss: 1.1308\n",
      "Epoch [1656/3000], Loss: 0.3179\n",
      "Epoch [1657/3000], Loss: 0.9847\n",
      "Epoch [1658/3000], Loss: 0.1057\n",
      "Epoch [1659/3000], Loss: 0.3215\n",
      "Epoch [1660/3000], Loss: 0.2364\n",
      "Epoch [1661/3000], Loss: 0.7342\n",
      "Epoch [1662/3000], Loss: 0.0193\n",
      "Epoch [1663/3000], Loss: 0.3859\n",
      "Epoch [1664/3000], Loss: 0.0639\n",
      "Epoch [1665/3000], Loss: 1.4570\n",
      "Epoch [1666/3000], Loss: 0.0857\n",
      "Epoch [1667/3000], Loss: 0.5069\n",
      "Epoch [1668/3000], Loss: 0.0508\n",
      "Epoch [1669/3000], Loss: 0.8566\n",
      "Epoch [1670/3000], Loss: 0.1791\n",
      "Epoch [1671/3000], Loss: 0.5131\n",
      "Epoch [1672/3000], Loss: 0.3685\n",
      "Epoch [1673/3000], Loss: 0.5878\n",
      "Epoch [1674/3000], Loss: 0.8083\n",
      "Epoch [1675/3000], Loss: 0.3520\n",
      "Epoch [1676/3000], Loss: 0.3271\n",
      "Epoch [1677/3000], Loss: 0.3687\n",
      "Epoch [1678/3000], Loss: 0.2562\n",
      "Epoch [1679/3000], Loss: 1.2100\n",
      "Epoch [1680/3000], Loss: 0.3803\n",
      "Epoch [1681/3000], Loss: 0.8002\n",
      "Epoch [1682/3000], Loss: 0.4520\n",
      "Epoch [1683/3000], Loss: 0.2056\n",
      "Epoch [1684/3000], Loss: 0.6517\n",
      "Epoch [1685/3000], Loss: 1.7512\n",
      "Epoch [1686/3000], Loss: 0.7634\n",
      "Epoch [1687/3000], Loss: 0.6531\n",
      "Epoch [1688/3000], Loss: 0.4704\n",
      "Epoch [1689/3000], Loss: 0.1220\n",
      "Epoch [1690/3000], Loss: 0.5221\n",
      "Epoch [1691/3000], Loss: 0.3107\n",
      "Epoch [1692/3000], Loss: 0.8019\n",
      "Epoch [1693/3000], Loss: 0.2728\n",
      "Epoch [1694/3000], Loss: 0.3861\n",
      "Epoch [1695/3000], Loss: 0.2347\n",
      "Epoch [1696/3000], Loss: 1.3450\n",
      "Epoch [1697/3000], Loss: 0.5828\n",
      "Epoch [1698/3000], Loss: 0.0440\n",
      "Epoch [1699/3000], Loss: 0.7939\n",
      "Epoch [1700/3000], Loss: 0.2965\n",
      "Epoch [1701/3000], Loss: 0.4951\n",
      "Epoch [1702/3000], Loss: 0.4193\n",
      "Epoch [1703/3000], Loss: 1.2558\n",
      "Epoch [1704/3000], Loss: 0.4306\n",
      "Epoch [1705/3000], Loss: 0.4004\n",
      "Epoch [1706/3000], Loss: 1.3986\n",
      "Epoch [1707/3000], Loss: 0.0895\n",
      "Epoch [1708/3000], Loss: 0.9070\n",
      "Epoch [1709/3000], Loss: 0.1338\n",
      "Epoch [1710/3000], Loss: 0.3885\n",
      "Epoch [1711/3000], Loss: 0.3545\n",
      "Epoch [1712/3000], Loss: 0.7505\n",
      "Epoch [1713/3000], Loss: 0.9539\n",
      "Epoch [1714/3000], Loss: 0.6250\n",
      "Epoch [1715/3000], Loss: 0.1097\n",
      "Epoch [1716/3000], Loss: 0.6745\n",
      "Epoch [1717/3000], Loss: 0.4702\n",
      "Epoch [1718/3000], Loss: 0.0354\n",
      "Epoch [1719/3000], Loss: 0.2061\n",
      "Epoch [1720/3000], Loss: 0.2860\n",
      "Epoch [1721/3000], Loss: 1.2596\n",
      "Epoch [1722/3000], Loss: 0.0993\n",
      "Epoch [1723/3000], Loss: 0.6284\n",
      "Epoch [1724/3000], Loss: 0.8305\n",
      "Epoch [1725/3000], Loss: 0.6044\n",
      "Epoch [1726/3000], Loss: 0.0253\n",
      "Epoch [1727/3000], Loss: 0.3422\n",
      "Epoch [1728/3000], Loss: 0.8152\n",
      "Epoch [1729/3000], Loss: 2.3958\n",
      "Epoch [1730/3000], Loss: 0.3453\n",
      "Epoch [1731/3000], Loss: 0.5937\n",
      "Epoch [1732/3000], Loss: 0.2702\n",
      "Epoch [1733/3000], Loss: 1.2613\n",
      "Epoch [1734/3000], Loss: 0.4646\n",
      "Epoch [1735/3000], Loss: 0.3111\n",
      "Epoch [1736/3000], Loss: 0.2276\n",
      "Epoch [1737/3000], Loss: 0.3463\n",
      "Epoch [1738/3000], Loss: 0.3421\n",
      "Epoch [1739/3000], Loss: 0.8649\n",
      "Epoch [1740/3000], Loss: 0.2426\n",
      "Epoch [1741/3000], Loss: 0.5206\n",
      "Epoch [1742/3000], Loss: 0.5349\n",
      "Epoch [1743/3000], Loss: 0.2142\n",
      "Epoch [1744/3000], Loss: 1.8676\n",
      "Epoch [1745/3000], Loss: 0.1935\n",
      "Epoch [1746/3000], Loss: 0.9968\n",
      "Epoch [1747/3000], Loss: 1.0117\n",
      "Epoch [1748/3000], Loss: 0.8228\n",
      "Epoch [1749/3000], Loss: 0.4942\n",
      "Epoch [1750/3000], Loss: 1.1107\n",
      "Epoch [1751/3000], Loss: 0.4673\n",
      "Epoch [1752/3000], Loss: 0.8509\n",
      "Epoch [1753/3000], Loss: 0.1643\n",
      "Epoch [1754/3000], Loss: 2.6212\n",
      "Epoch [1755/3000], Loss: 1.6996\n",
      "Epoch [1756/3000], Loss: 0.6247\n",
      "Epoch [1757/3000], Loss: 0.4256\n",
      "Epoch [1758/3000], Loss: 0.0134\n",
      "Epoch [1759/3000], Loss: 1.1332\n",
      "Epoch [1760/3000], Loss: 1.0853\n",
      "Epoch [1761/3000], Loss: 0.7731\n",
      "Epoch [1762/3000], Loss: 0.4461\n",
      "Epoch [1763/3000], Loss: 0.3027\n",
      "Epoch [1764/3000], Loss: 0.2294\n",
      "Epoch [1765/3000], Loss: 0.3600\n",
      "Epoch [1766/3000], Loss: 0.3475\n",
      "Epoch [1767/3000], Loss: 0.2353\n",
      "Epoch [1768/3000], Loss: 0.5194\n",
      "Epoch [1769/3000], Loss: 0.3313\n",
      "Epoch [1770/3000], Loss: 0.5365\n",
      "Epoch [1771/3000], Loss: 0.2560\n",
      "Epoch [1772/3000], Loss: 0.9176\n",
      "Epoch [1773/3000], Loss: 1.1888\n",
      "Epoch [1774/3000], Loss: 0.5229\n",
      "Epoch [1775/3000], Loss: 0.4598\n",
      "Epoch [1776/3000], Loss: 0.1410\n",
      "Epoch [1777/3000], Loss: 0.1921\n",
      "Epoch [1778/3000], Loss: 0.0100\n",
      "Epoch [1779/3000], Loss: 0.2527\n",
      "Epoch [1780/3000], Loss: 0.1171\n",
      "Epoch [1781/3000], Loss: 0.2369\n",
      "Epoch [1782/3000], Loss: 0.1209\n",
      "Epoch [1783/3000], Loss: 0.3477\n",
      "Epoch [1784/3000], Loss: 0.5427\n",
      "Epoch [1785/3000], Loss: 0.3357\n",
      "Epoch [1786/3000], Loss: 0.3528\n",
      "Epoch [1787/3000], Loss: 0.4022\n",
      "Epoch [1788/3000], Loss: 0.0842\n",
      "Epoch [1789/3000], Loss: 0.1076\n",
      "Epoch [1790/3000], Loss: 0.1760\n",
      "Epoch [1791/3000], Loss: 0.0752\n",
      "Epoch [1792/3000], Loss: 0.7030\n",
      "Epoch [1793/3000], Loss: 0.9242\n",
      "Epoch [1794/3000], Loss: 1.1884\n",
      "Epoch [1795/3000], Loss: 0.2035\n",
      "Epoch [1796/3000], Loss: 0.2521\n",
      "Epoch [1797/3000], Loss: 0.6034\n",
      "Epoch [1798/3000], Loss: 0.2464\n",
      "Epoch [1799/3000], Loss: 0.5185\n",
      "Epoch [1800/3000], Loss: 0.3472\n",
      "Epoch [1801/3000], Loss: 0.5190\n",
      "Epoch [1802/3000], Loss: 0.7004\n",
      "Epoch [1803/3000], Loss: 0.0981\n",
      "Epoch [1804/3000], Loss: 0.8227\n",
      "Epoch [1805/3000], Loss: 1.1986\n",
      "Epoch [1806/3000], Loss: 0.2766\n",
      "Epoch [1807/3000], Loss: 1.6471\n",
      "Epoch [1808/3000], Loss: 0.6916\n",
      "Epoch [1809/3000], Loss: 0.2411\n",
      "Epoch [1810/3000], Loss: 0.1417\n",
      "Epoch [1811/3000], Loss: 0.5574\n",
      "Epoch [1812/3000], Loss: 0.0042\n",
      "Epoch [1813/3000], Loss: 0.3202\n",
      "Epoch [1814/3000], Loss: 0.4287\n",
      "Epoch [1815/3000], Loss: 0.2759\n",
      "Epoch [1816/3000], Loss: 1.3437\n",
      "Epoch [1817/3000], Loss: 0.4334\n",
      "Epoch [1818/3000], Loss: 0.3911\n",
      "Epoch [1819/3000], Loss: 0.0250\n",
      "Epoch [1820/3000], Loss: 0.4629\n",
      "Epoch [1821/3000], Loss: 0.1315\n",
      "Epoch [1822/3000], Loss: 0.2021\n",
      "Epoch [1823/3000], Loss: 0.1426\n",
      "Epoch [1824/3000], Loss: 2.2439\n",
      "Epoch [1825/3000], Loss: 0.9572\n",
      "Epoch [1826/3000], Loss: 1.1487\n",
      "Epoch [1827/3000], Loss: 0.8301\n",
      "Epoch [1828/3000], Loss: 0.3381\n",
      "Epoch [1829/3000], Loss: 0.3095\n",
      "Epoch [1830/3000], Loss: 0.3167\n",
      "Epoch [1831/3000], Loss: 0.4144\n",
      "Epoch [1832/3000], Loss: 0.6285\n",
      "Epoch [1833/3000], Loss: 1.2516\n",
      "Epoch [1834/3000], Loss: 0.8038\n",
      "Epoch [1835/3000], Loss: 0.0380\n",
      "Epoch [1836/3000], Loss: 0.2142\n",
      "Epoch [1837/3000], Loss: 0.1968\n",
      "Epoch [1838/3000], Loss: 0.5797\n",
      "Epoch [1839/3000], Loss: 0.3763\n",
      "Epoch [1840/3000], Loss: 1.3794\n",
      "Epoch [1841/3000], Loss: 1.0914\n",
      "Epoch [1842/3000], Loss: 1.7338\n",
      "Epoch [1843/3000], Loss: 1.2354\n",
      "Epoch [1844/3000], Loss: 0.3982\n",
      "Epoch [1845/3000], Loss: 0.1305\n",
      "Epoch [1846/3000], Loss: 0.0330\n",
      "Epoch [1847/3000], Loss: 0.0956\n",
      "Epoch [1848/3000], Loss: 0.1076\n",
      "Epoch [1849/3000], Loss: 0.3324\n",
      "Epoch [1850/3000], Loss: 0.7107\n",
      "Epoch [1851/3000], Loss: 0.3238\n",
      "Epoch [1852/3000], Loss: 0.6010\n",
      "Epoch [1853/3000], Loss: 0.3186\n",
      "Epoch [1854/3000], Loss: 0.3829\n",
      "Epoch [1855/3000], Loss: 0.4012\n",
      "Epoch [1856/3000], Loss: 1.9139\n",
      "Epoch [1857/3000], Loss: 0.6283\n",
      "Epoch [1858/3000], Loss: 0.2872\n",
      "Epoch [1859/3000], Loss: 0.2372\n",
      "Epoch [1860/3000], Loss: 0.1829\n",
      "Epoch [1861/3000], Loss: 0.3478\n",
      "Epoch [1862/3000], Loss: 1.0226\n",
      "Epoch [1863/3000], Loss: 0.8933\n",
      "Epoch [1864/3000], Loss: 0.7965\n",
      "Epoch [1865/3000], Loss: 0.2949\n",
      "Epoch [1866/3000], Loss: 0.5187\n",
      "Epoch [1867/3000], Loss: 0.0185\n",
      "Epoch [1868/3000], Loss: 0.3724\n",
      "Epoch [1869/3000], Loss: 0.2195\n",
      "Epoch [1870/3000], Loss: 0.3380\n",
      "Epoch [1871/3000], Loss: 0.5876\n",
      "Epoch [1872/3000], Loss: 0.0929\n",
      "Epoch [1873/3000], Loss: 0.4824\n",
      "Epoch [1874/3000], Loss: 0.4983\n",
      "Epoch [1875/3000], Loss: 1.5685\n",
      "Epoch [1876/3000], Loss: 0.7152\n",
      "Epoch [1877/3000], Loss: 0.1953\n",
      "Epoch [1878/3000], Loss: 0.1573\n",
      "Epoch [1879/3000], Loss: 0.1155\n",
      "Epoch [1880/3000], Loss: 0.0503\n",
      "Epoch [1881/3000], Loss: 0.9585\n",
      "Epoch [1882/3000], Loss: 0.5515\n",
      "Epoch [1883/3000], Loss: 0.6063\n",
      "Epoch [1884/3000], Loss: 0.5658\n",
      "Epoch [1885/3000], Loss: 0.3956\n",
      "Epoch [1886/3000], Loss: 1.1071\n",
      "Epoch [1887/3000], Loss: 0.7210\n",
      "Epoch [1888/3000], Loss: 0.3005\n",
      "Epoch [1889/3000], Loss: 0.2305\n",
      "Epoch [1890/3000], Loss: 0.4253\n",
      "Epoch [1891/3000], Loss: 0.2761\n",
      "Epoch [1892/3000], Loss: 0.2151\n",
      "Epoch [1893/3000], Loss: 0.1135\n",
      "Epoch [1894/3000], Loss: 0.3808\n",
      "Epoch [1895/3000], Loss: 0.8445\n",
      "Epoch [1896/3000], Loss: 0.1028\n",
      "Epoch [1897/3000], Loss: 0.3438\n",
      "Epoch [1898/3000], Loss: 0.6581\n",
      "Epoch [1899/3000], Loss: 0.9027\n",
      "Epoch [1900/3000], Loss: 0.2111\n",
      "Epoch [1901/3000], Loss: 1.2971\n",
      "Epoch [1902/3000], Loss: 0.6003\n",
      "Epoch [1903/3000], Loss: 0.5787\n",
      "Epoch [1904/3000], Loss: 1.0722\n",
      "Epoch [1905/3000], Loss: 0.4441\n",
      "Epoch [1906/3000], Loss: 0.6811\n",
      "Epoch [1907/3000], Loss: 1.4516\n",
      "Epoch [1908/3000], Loss: 0.2809\n",
      "Epoch [1909/3000], Loss: 0.1297\n",
      "Epoch [1910/3000], Loss: 0.4532\n",
      "Epoch [1911/3000], Loss: 0.2263\n",
      "Epoch [1912/3000], Loss: 0.3777\n",
      "Epoch [1913/3000], Loss: 0.6991\n",
      "Epoch [1914/3000], Loss: 1.0910\n",
      "Epoch [1915/3000], Loss: 0.1157\n",
      "Epoch [1916/3000], Loss: 1.2356\n",
      "Epoch [1917/3000], Loss: 0.2043\n",
      "Epoch [1918/3000], Loss: 0.3280\n",
      "Epoch [1919/3000], Loss: 0.7379\n",
      "Epoch [1920/3000], Loss: 1.9918\n",
      "Epoch [1921/3000], Loss: 0.2116\n",
      "Epoch [1922/3000], Loss: 1.0743\n",
      "Epoch [1923/3000], Loss: 1.0648\n",
      "Epoch [1924/3000], Loss: 1.3598\n",
      "Epoch [1925/3000], Loss: 0.0985\n",
      "Epoch [1926/3000], Loss: 0.7099\n",
      "Epoch [1927/3000], Loss: 0.7149\n",
      "Epoch [1928/3000], Loss: 0.4792\n",
      "Epoch [1929/3000], Loss: 0.5015\n",
      "Epoch [1930/3000], Loss: 0.0087\n",
      "Epoch [1931/3000], Loss: 0.7539\n",
      "Epoch [1932/3000], Loss: 0.7443\n",
      "Epoch [1933/3000], Loss: 0.2720\n",
      "Epoch [1934/3000], Loss: 0.6373\n",
      "Epoch [1935/3000], Loss: 1.2188\n",
      "Epoch [1936/3000], Loss: 0.3984\n",
      "Epoch [1937/3000], Loss: 0.2650\n",
      "Epoch [1938/3000], Loss: 0.1369\n",
      "Epoch [1939/3000], Loss: 0.1638\n",
      "Epoch [1940/3000], Loss: 0.1985\n",
      "Epoch [1941/3000], Loss: 0.6801\n",
      "Epoch [1942/3000], Loss: 0.0962\n",
      "Epoch [1943/3000], Loss: 0.1954\n",
      "Epoch [1944/3000], Loss: 0.1562\n",
      "Epoch [1945/3000], Loss: 1.2351\n",
      "Epoch [1946/3000], Loss: 0.3117\n",
      "Epoch [1947/3000], Loss: 0.4450\n",
      "Epoch [1948/3000], Loss: 0.3347\n",
      "Epoch [1949/3000], Loss: 0.9826\n",
      "Epoch [1950/3000], Loss: 1.0945\n",
      "Epoch [1951/3000], Loss: 0.2705\n",
      "Epoch [1952/3000], Loss: 0.2327\n",
      "Epoch [1953/3000], Loss: 0.6116\n",
      "Epoch [1954/3000], Loss: 0.0124\n",
      "Epoch [1955/3000], Loss: 0.2867\n",
      "Epoch [1956/3000], Loss: 0.3666\n",
      "Epoch [1957/3000], Loss: 0.0997\n",
      "Epoch [1958/3000], Loss: 0.4062\n",
      "Epoch [1959/3000], Loss: 0.4418\n",
      "Epoch [1960/3000], Loss: 0.6476\n",
      "Epoch [1961/3000], Loss: 0.0579\n",
      "Epoch [1962/3000], Loss: 0.6048\n",
      "Epoch [1963/3000], Loss: 0.6658\n",
      "Epoch [1964/3000], Loss: 0.8139\n",
      "Epoch [1965/3000], Loss: 1.4273\n",
      "Epoch [1966/3000], Loss: 0.0849\n",
      "Epoch [1967/3000], Loss: 0.4543\n",
      "Epoch [1968/3000], Loss: 1.0887\n",
      "Epoch [1969/3000], Loss: 0.0127\n",
      "Epoch [1970/3000], Loss: 0.4516\n",
      "Epoch [1971/3000], Loss: 0.8687\n",
      "Epoch [1972/3000], Loss: 0.6146\n",
      "Epoch [1973/3000], Loss: 0.0053\n",
      "Epoch [1974/3000], Loss: 1.1663\n",
      "Epoch [1975/3000], Loss: 0.0901\n",
      "Epoch [1976/3000], Loss: 1.1568\n",
      "Epoch [1977/3000], Loss: 2.2894\n",
      "Epoch [1978/3000], Loss: 0.4451\n",
      "Epoch [1979/3000], Loss: 1.0382\n",
      "Epoch [1980/3000], Loss: 1.2578\n",
      "Epoch [1981/3000], Loss: 2.3693\n",
      "Epoch [1982/3000], Loss: 0.1178\n",
      "Epoch [1983/3000], Loss: 0.3550\n",
      "Epoch [1984/3000], Loss: 1.9527\n",
      "Epoch [1985/3000], Loss: 0.4179\n",
      "Epoch [1986/3000], Loss: 0.0537\n",
      "Epoch [1987/3000], Loss: 0.1446\n",
      "Epoch [1988/3000], Loss: 0.4871\n",
      "Epoch [1989/3000], Loss: 1.1708\n",
      "Epoch [1990/3000], Loss: 0.2964\n",
      "Epoch [1991/3000], Loss: 0.6902\n",
      "Epoch [1992/3000], Loss: 0.6222\n",
      "Epoch [1993/3000], Loss: 0.1644\n",
      "Epoch [1994/3000], Loss: 0.2584\n",
      "Epoch [1995/3000], Loss: 0.8403\n",
      "Epoch [1996/3000], Loss: 1.7676\n",
      "Epoch [1997/3000], Loss: 0.2794\n",
      "Epoch [1998/3000], Loss: 0.1612\n",
      "Epoch [1999/3000], Loss: 0.1577\n",
      "Epoch [2000/3000], Loss: 0.4062\n",
      "Epoch [2001/3000], Loss: 0.5342\n",
      "Epoch [2002/3000], Loss: 0.3491\n",
      "Epoch [2003/3000], Loss: 1.0431\n",
      "Epoch [2004/3000], Loss: 1.1089\n",
      "Epoch [2005/3000], Loss: 0.3307\n",
      "Epoch [2006/3000], Loss: 0.5439\n",
      "Epoch [2007/3000], Loss: 0.1051\n",
      "Epoch [2008/3000], Loss: 0.1718\n",
      "Epoch [2009/3000], Loss: 0.7119\n",
      "Epoch [2010/3000], Loss: 0.9466\n",
      "Epoch [2011/3000], Loss: 0.5686\n",
      "Epoch [2012/3000], Loss: 1.1928\n",
      "Epoch [2013/3000], Loss: 1.6872\n",
      "Epoch [2014/3000], Loss: 0.3528\n",
      "Epoch [2015/3000], Loss: 3.0438\n",
      "Epoch [2016/3000], Loss: 0.0211\n",
      "Epoch [2017/3000], Loss: 1.2657\n",
      "Epoch [2018/3000], Loss: 0.0839\n",
      "Epoch [2019/3000], Loss: 0.6913\n",
      "Epoch [2020/3000], Loss: 0.0654\n",
      "Epoch [2021/3000], Loss: 0.3296\n",
      "Epoch [2022/3000], Loss: 0.0541\n",
      "Epoch [2023/3000], Loss: 0.9895\n",
      "Epoch [2024/3000], Loss: 0.1865\n",
      "Epoch [2025/3000], Loss: 1.9394\n",
      "Epoch [2026/3000], Loss: 0.2011\n",
      "Epoch [2027/3000], Loss: 0.6344\n",
      "Epoch [2028/3000], Loss: 0.1936\n",
      "Epoch [2029/3000], Loss: 0.5622\n",
      "Epoch [2030/3000], Loss: 0.7312\n",
      "Epoch [2031/3000], Loss: 0.8372\n",
      "Epoch [2032/3000], Loss: 1.4126\n",
      "Epoch [2033/3000], Loss: 0.4009\n",
      "Epoch [2034/3000], Loss: 0.8944\n",
      "Epoch [2035/3000], Loss: 0.6351\n",
      "Epoch [2036/3000], Loss: 0.7446\n",
      "Epoch [2037/3000], Loss: 1.1507\n",
      "Epoch [2038/3000], Loss: 1.4323\n",
      "Epoch [2039/3000], Loss: 0.4920\n",
      "Epoch [2040/3000], Loss: 0.1938\n",
      "Epoch [2041/3000], Loss: 1.2319\n",
      "Epoch [2042/3000], Loss: 0.5608\n",
      "Epoch [2043/3000], Loss: 0.7041\n",
      "Epoch [2044/3000], Loss: 0.4751\n",
      "Epoch [2045/3000], Loss: 0.5808\n",
      "Epoch [2046/3000], Loss: 1.4877\n",
      "Epoch [2047/3000], Loss: 1.5259\n",
      "Epoch [2048/3000], Loss: 1.0061\n",
      "Epoch [2049/3000], Loss: 1.1228\n",
      "Epoch [2050/3000], Loss: 0.1383\n",
      "Epoch [2051/3000], Loss: 0.8313\n",
      "Epoch [2052/3000], Loss: 0.8052\n",
      "Epoch [2053/3000], Loss: 0.4334\n",
      "Epoch [2054/3000], Loss: 1.0059\n",
      "Epoch [2055/3000], Loss: 0.5131\n",
      "Epoch [2056/3000], Loss: 0.6593\n",
      "Epoch [2057/3000], Loss: 0.8361\n",
      "Epoch [2058/3000], Loss: 0.1526\n",
      "Epoch [2059/3000], Loss: 0.8742\n",
      "Epoch [2060/3000], Loss: 0.4093\n",
      "Epoch [2061/3000], Loss: 0.5260\n",
      "Epoch [2062/3000], Loss: 1.2460\n",
      "Epoch [2063/3000], Loss: 0.3385\n",
      "Epoch [2064/3000], Loss: 0.5739\n",
      "Epoch [2065/3000], Loss: 0.7531\n",
      "Epoch [2066/3000], Loss: 0.4039\n",
      "Epoch [2067/3000], Loss: 0.2625\n",
      "Epoch [2068/3000], Loss: 0.3277\n",
      "Epoch [2069/3000], Loss: 0.3484\n",
      "Epoch [2070/3000], Loss: 0.6113\n",
      "Epoch [2071/3000], Loss: 0.6804\n",
      "Epoch [2072/3000], Loss: 0.4669\n",
      "Epoch [2073/3000], Loss: 0.0823\n",
      "Epoch [2074/3000], Loss: 0.0432\n",
      "Epoch [2075/3000], Loss: 0.3982\n",
      "Epoch [2076/3000], Loss: 0.6318\n",
      "Epoch [2077/3000], Loss: 1.5611\n",
      "Epoch [2078/3000], Loss: 1.2370\n",
      "Epoch [2079/3000], Loss: 0.0543\n",
      "Epoch [2080/3000], Loss: 0.2804\n",
      "Epoch [2081/3000], Loss: 0.1755\n",
      "Epoch [2082/3000], Loss: 0.0915\n",
      "Epoch [2083/3000], Loss: 0.6927\n",
      "Epoch [2084/3000], Loss: 0.3315\n",
      "Epoch [2085/3000], Loss: 0.7137\n",
      "Epoch [2086/3000], Loss: 0.3743\n",
      "Epoch [2087/3000], Loss: 0.2570\n",
      "Epoch [2088/3000], Loss: 0.4286\n",
      "Epoch [2089/3000], Loss: 0.2501\n",
      "Epoch [2090/3000], Loss: 1.1196\n",
      "Epoch [2091/3000], Loss: 0.1320\n",
      "Epoch [2092/3000], Loss: 0.2385\n",
      "Epoch [2093/3000], Loss: 0.1434\n",
      "Epoch [2094/3000], Loss: 0.5362\n",
      "Epoch [2095/3000], Loss: 0.2743\n",
      "Epoch [2096/3000], Loss: 0.6762\n",
      "Epoch [2097/3000], Loss: 0.2204\n",
      "Epoch [2098/3000], Loss: 0.2206\n",
      "Epoch [2099/3000], Loss: 0.7018\n",
      "Epoch [2100/3000], Loss: 0.4395\n",
      "Epoch [2101/3000], Loss: 1.4502\n",
      "Epoch [2102/3000], Loss: 0.3848\n",
      "Epoch [2103/3000], Loss: 1.0614\n",
      "Epoch [2104/3000], Loss: 0.2129\n",
      "Epoch [2105/3000], Loss: 1.1749\n",
      "Epoch [2106/3000], Loss: 0.2144\n",
      "Epoch [2107/3000], Loss: 1.7385\n",
      "Epoch [2108/3000], Loss: 0.2372\n",
      "Epoch [2109/3000], Loss: 0.7035\n",
      "Epoch [2110/3000], Loss: 0.0441\n",
      "Epoch [2111/3000], Loss: 0.5694\n",
      "Epoch [2112/3000], Loss: 0.8314\n",
      "Epoch [2113/3000], Loss: 0.4424\n",
      "Epoch [2114/3000], Loss: 0.4158\n",
      "Epoch [2115/3000], Loss: 0.5872\n",
      "Epoch [2116/3000], Loss: 0.3109\n",
      "Epoch [2117/3000], Loss: 1.0792\n",
      "Epoch [2118/3000], Loss: 0.0499\n",
      "Epoch [2119/3000], Loss: 0.2641\n",
      "Epoch [2120/3000], Loss: 0.1482\n",
      "Epoch [2121/3000], Loss: 0.2887\n",
      "Epoch [2122/3000], Loss: 1.1546\n",
      "Epoch [2123/3000], Loss: 0.8699\n",
      "Epoch [2124/3000], Loss: 0.2619\n",
      "Epoch [2125/3000], Loss: 0.0695\n",
      "Epoch [2126/3000], Loss: 0.0127\n",
      "Epoch [2127/3000], Loss: 0.8713\n",
      "Epoch [2128/3000], Loss: 0.3691\n",
      "Epoch [2129/3000], Loss: 0.4654\n",
      "Epoch [2130/3000], Loss: 0.2725\n",
      "Epoch [2131/3000], Loss: 0.3185\n",
      "Epoch [2132/3000], Loss: 1.2271\n",
      "Epoch [2133/3000], Loss: 0.4148\n",
      "Epoch [2134/3000], Loss: 0.1888\n",
      "Epoch [2135/3000], Loss: 0.4253\n",
      "Epoch [2136/3000], Loss: 0.5246\n",
      "Epoch [2137/3000], Loss: 0.0460\n",
      "Epoch [2138/3000], Loss: 1.3114\n",
      "Epoch [2139/3000], Loss: 2.3870\n",
      "Epoch [2140/3000], Loss: 1.7188\n",
      "Epoch [2141/3000], Loss: 0.3289\n",
      "Epoch [2142/3000], Loss: 0.5780\n",
      "Epoch [2143/3000], Loss: 0.3432\n",
      "Epoch [2144/3000], Loss: 0.1135\n",
      "Epoch [2145/3000], Loss: 0.1638\n",
      "Epoch [2146/3000], Loss: 0.8658\n",
      "Epoch [2147/3000], Loss: 1.2376\n",
      "Epoch [2148/3000], Loss: 0.0601\n",
      "Epoch [2149/3000], Loss: 0.5232\n",
      "Epoch [2150/3000], Loss: 0.0117\n",
      "Epoch [2151/3000], Loss: 1.3302\n",
      "Epoch [2152/3000], Loss: 0.3867\n",
      "Epoch [2153/3000], Loss: 0.9813\n",
      "Epoch [2154/3000], Loss: 0.0208\n",
      "Epoch [2155/3000], Loss: 1.1052\n",
      "Epoch [2156/3000], Loss: 0.1224\n",
      "Epoch [2157/3000], Loss: 0.3987\n",
      "Epoch [2158/3000], Loss: 0.7454\n",
      "Epoch [2159/3000], Loss: 0.0792\n",
      "Epoch [2160/3000], Loss: 0.2230\n",
      "Epoch [2161/3000], Loss: 0.0334\n",
      "Epoch [2162/3000], Loss: 0.5433\n",
      "Epoch [2163/3000], Loss: 1.6253\n",
      "Epoch [2164/3000], Loss: 0.4707\n",
      "Epoch [2165/3000], Loss: 0.1421\n",
      "Epoch [2166/3000], Loss: 0.5830\n",
      "Epoch [2167/3000], Loss: 0.5588\n",
      "Epoch [2168/3000], Loss: 0.5054\n",
      "Epoch [2169/3000], Loss: 0.5385\n",
      "Epoch [2170/3000], Loss: 0.6339\n",
      "Epoch [2171/3000], Loss: 1.2346\n",
      "Epoch [2172/3000], Loss: 0.4013\n",
      "Epoch [2173/3000], Loss: 1.1462\n",
      "Epoch [2174/3000], Loss: 0.0825\n",
      "Epoch [2175/3000], Loss: 0.5657\n",
      "Epoch [2176/3000], Loss: 0.5825\n",
      "Epoch [2177/3000], Loss: 0.1529\n",
      "Epoch [2178/3000], Loss: 0.4688\n",
      "Epoch [2179/3000], Loss: 0.8241\n",
      "Epoch [2180/3000], Loss: 0.1825\n",
      "Epoch [2181/3000], Loss: 0.3587\n",
      "Epoch [2182/3000], Loss: 0.3841\n",
      "Epoch [2183/3000], Loss: 0.2676\n",
      "Epoch [2184/3000], Loss: 0.8566\n",
      "Epoch [2185/3000], Loss: 0.8881\n",
      "Epoch [2186/3000], Loss: 0.7345\n",
      "Epoch [2187/3000], Loss: 0.1549\n",
      "Epoch [2188/3000], Loss: 0.0127\n",
      "Epoch [2189/3000], Loss: 1.2001\n",
      "Epoch [2190/3000], Loss: 1.3646\n",
      "Epoch [2191/3000], Loss: 0.2032\n",
      "Epoch [2192/3000], Loss: 1.2602\n",
      "Epoch [2193/3000], Loss: 1.1922\n",
      "Epoch [2194/3000], Loss: 0.3822\n",
      "Epoch [2195/3000], Loss: 0.2850\n",
      "Epoch [2196/3000], Loss: 0.2009\n",
      "Epoch [2197/3000], Loss: 0.2850\n",
      "Epoch [2198/3000], Loss: 0.6160\n",
      "Epoch [2199/3000], Loss: 0.5468\n",
      "Epoch [2200/3000], Loss: 0.1321\n",
      "Epoch [2201/3000], Loss: 0.4974\n",
      "Epoch [2202/3000], Loss: 1.3228\n",
      "Epoch [2203/3000], Loss: 0.5117\n",
      "Epoch [2204/3000], Loss: 0.4060\n",
      "Epoch [2205/3000], Loss: 0.8573\n",
      "Epoch [2206/3000], Loss: 0.6207\n",
      "Epoch [2207/3000], Loss: 0.5372\n",
      "Epoch [2208/3000], Loss: 0.1822\n",
      "Epoch [2209/3000], Loss: 1.6813\n",
      "Epoch [2210/3000], Loss: 0.4220\n",
      "Epoch [2211/3000], Loss: 0.1217\n",
      "Epoch [2212/3000], Loss: 0.3438\n",
      "Epoch [2213/3000], Loss: 0.2046\n",
      "Epoch [2214/3000], Loss: 0.0533\n",
      "Epoch [2215/3000], Loss: 0.4499\n",
      "Epoch [2216/3000], Loss: 0.3304\n",
      "Epoch [2217/3000], Loss: 0.8128\n",
      "Epoch [2218/3000], Loss: 0.8374\n",
      "Epoch [2219/3000], Loss: 0.9309\n",
      "Epoch [2220/3000], Loss: 0.6218\n",
      "Epoch [2221/3000], Loss: 0.0331\n",
      "Epoch [2222/3000], Loss: 0.2930\n",
      "Epoch [2223/3000], Loss: 0.0815\n",
      "Epoch [2224/3000], Loss: 1.1005\n",
      "Epoch [2225/3000], Loss: 0.0459\n",
      "Epoch [2226/3000], Loss: 0.0316\n",
      "Epoch [2227/3000], Loss: 0.5681\n",
      "Epoch [2228/3000], Loss: 3.6683\n",
      "Epoch [2229/3000], Loss: 1.1246\n",
      "Epoch [2230/3000], Loss: 1.1608\n",
      "Epoch [2231/3000], Loss: 0.7134\n",
      "Epoch [2232/3000], Loss: 0.5663\n",
      "Epoch [2233/3000], Loss: 1.1718\n",
      "Epoch [2234/3000], Loss: 0.0930\n",
      "Epoch [2235/3000], Loss: 0.8162\n",
      "Epoch [2236/3000], Loss: 0.4333\n",
      "Epoch [2237/3000], Loss: 0.0349\n",
      "Epoch [2238/3000], Loss: 0.0123\n",
      "Epoch [2239/3000], Loss: 0.2620\n",
      "Epoch [2240/3000], Loss: 0.1843\n",
      "Epoch [2241/3000], Loss: 1.0374\n",
      "Epoch [2242/3000], Loss: 0.2220\n",
      "Epoch [2243/3000], Loss: 0.7451\n",
      "Epoch [2244/3000], Loss: 0.8978\n",
      "Epoch [2245/3000], Loss: 0.5033\n",
      "Epoch [2246/3000], Loss: 0.3201\n",
      "Epoch [2247/3000], Loss: 0.5094\n",
      "Epoch [2248/3000], Loss: 0.5890\n",
      "Epoch [2249/3000], Loss: 0.4380\n",
      "Epoch [2250/3000], Loss: 1.9026\n",
      "Epoch [2251/3000], Loss: 0.4392\n",
      "Epoch [2252/3000], Loss: 0.3104\n",
      "Epoch [2253/3000], Loss: 1.4886\n",
      "Epoch [2254/3000], Loss: 0.5968\n",
      "Epoch [2255/3000], Loss: 0.2077\n",
      "Epoch [2256/3000], Loss: 0.6783\n",
      "Epoch [2257/3000], Loss: 0.7386\n",
      "Epoch [2258/3000], Loss: 0.7830\n",
      "Epoch [2259/3000], Loss: 0.1542\n",
      "Epoch [2260/3000], Loss: 0.1306\n",
      "Epoch [2261/3000], Loss: 0.0450\n",
      "Epoch [2262/3000], Loss: 0.3064\n",
      "Epoch [2263/3000], Loss: 0.1975\n",
      "Epoch [2264/3000], Loss: 0.1609\n",
      "Epoch [2265/3000], Loss: 0.5497\n",
      "Epoch [2266/3000], Loss: 0.0685\n",
      "Epoch [2267/3000], Loss: 0.2039\n",
      "Epoch [2268/3000], Loss: 0.3751\n",
      "Epoch [2269/3000], Loss: 0.8456\n",
      "Epoch [2270/3000], Loss: 0.0910\n",
      "Epoch [2271/3000], Loss: 0.8004\n",
      "Epoch [2272/3000], Loss: 0.0438\n",
      "Epoch [2273/3000], Loss: 1.9758\n",
      "Epoch [2274/3000], Loss: 0.1385\n",
      "Epoch [2275/3000], Loss: 0.2455\n",
      "Epoch [2276/3000], Loss: 0.1958\n",
      "Epoch [2277/3000], Loss: 0.5837\n",
      "Epoch [2278/3000], Loss: 0.3899\n",
      "Epoch [2279/3000], Loss: 1.1513\n",
      "Epoch [2280/3000], Loss: 0.6991\n",
      "Epoch [2281/3000], Loss: 0.9604\n",
      "Epoch [2282/3000], Loss: 0.2864\n",
      "Epoch [2283/3000], Loss: 0.1802\n",
      "Epoch [2284/3000], Loss: 0.1865\n",
      "Epoch [2285/3000], Loss: 0.5279\n",
      "Epoch [2286/3000], Loss: 0.7810\n",
      "Epoch [2287/3000], Loss: 0.2864\n",
      "Epoch [2288/3000], Loss: 3.5325\n",
      "Epoch [2289/3000], Loss: 0.4038\n",
      "Epoch [2290/3000], Loss: 1.5906\n",
      "Epoch [2291/3000], Loss: 0.1801\n",
      "Epoch [2292/3000], Loss: 0.2994\n",
      "Epoch [2293/3000], Loss: 0.2756\n",
      "Epoch [2294/3000], Loss: 0.3494\n",
      "Epoch [2295/3000], Loss: 0.2069\n",
      "Epoch [2296/3000], Loss: 0.3957\n",
      "Epoch [2297/3000], Loss: 0.5595\n",
      "Epoch [2298/3000], Loss: 0.2323\n",
      "Epoch [2299/3000], Loss: 0.1480\n",
      "Epoch [2300/3000], Loss: 1.5417\n",
      "Epoch [2301/3000], Loss: 0.2595\n",
      "Epoch [2302/3000], Loss: 1.4052\n",
      "Epoch [2303/3000], Loss: 0.1289\n",
      "Epoch [2304/3000], Loss: 0.0243\n",
      "Epoch [2305/3000], Loss: 1.4893\n",
      "Epoch [2306/3000], Loss: 0.8332\n",
      "Epoch [2307/3000], Loss: 0.5738\n",
      "Epoch [2308/3000], Loss: 0.2692\n",
      "Epoch [2309/3000], Loss: 0.4746\n",
      "Epoch [2310/3000], Loss: 0.7977\n",
      "Epoch [2311/3000], Loss: 1.2490\n",
      "Epoch [2312/3000], Loss: 0.8760\n",
      "Epoch [2313/3000], Loss: 0.0907\n",
      "Epoch [2314/3000], Loss: 1.9278\n",
      "Epoch [2315/3000], Loss: 0.2416\n",
      "Epoch [2316/3000], Loss: 1.0514\n",
      "Epoch [2317/3000], Loss: 0.3016\n",
      "Epoch [2318/3000], Loss: 0.1520\n",
      "Epoch [2319/3000], Loss: 0.2498\n",
      "Epoch [2320/3000], Loss: 0.4979\n",
      "Epoch [2321/3000], Loss: 0.4954\n",
      "Epoch [2322/3000], Loss: 1.0939\n",
      "Epoch [2323/3000], Loss: 0.2380\n",
      "Epoch [2324/3000], Loss: 0.9095\n",
      "Epoch [2325/3000], Loss: 0.5803\n",
      "Epoch [2326/3000], Loss: 1.2286\n",
      "Epoch [2327/3000], Loss: 1.0132\n",
      "Epoch [2328/3000], Loss: 1.8511\n",
      "Epoch [2329/3000], Loss: 0.0957\n",
      "Epoch [2330/3000], Loss: 1.3690\n",
      "Epoch [2331/3000], Loss: 0.8462\n",
      "Epoch [2332/3000], Loss: 0.8306\n",
      "Epoch [2333/3000], Loss: 0.2306\n",
      "Epoch [2334/3000], Loss: 0.6669\n",
      "Epoch [2335/3000], Loss: 0.0973\n",
      "Epoch [2336/3000], Loss: 0.7062\n",
      "Epoch [2337/3000], Loss: 0.7358\n",
      "Epoch [2338/3000], Loss: 0.5523\n",
      "Epoch [2339/3000], Loss: 0.1596\n",
      "Epoch [2340/3000], Loss: 0.6262\n",
      "Epoch [2341/3000], Loss: 0.1368\n",
      "Epoch [2342/3000], Loss: 0.5014\n",
      "Epoch [2343/3000], Loss: 0.1144\n",
      "Epoch [2344/3000], Loss: 0.0214\n",
      "Epoch [2345/3000], Loss: 0.3762\n",
      "Epoch [2346/3000], Loss: 1.4713\n",
      "Epoch [2347/3000], Loss: 0.4098\n",
      "Epoch [2348/3000], Loss: 0.2400\n",
      "Epoch [2349/3000], Loss: 0.8794\n",
      "Epoch [2350/3000], Loss: 0.5268\n",
      "Epoch [2351/3000], Loss: 0.9326\n",
      "Epoch [2352/3000], Loss: 0.2460\n",
      "Epoch [2353/3000], Loss: 1.6646\n",
      "Epoch [2354/3000], Loss: 1.1493\n",
      "Epoch [2355/3000], Loss: 0.4648\n",
      "Epoch [2356/3000], Loss: 0.9491\n",
      "Epoch [2357/3000], Loss: 0.6102\n",
      "Epoch [2358/3000], Loss: 2.2068\n",
      "Epoch [2359/3000], Loss: 0.2512\n",
      "Epoch [2360/3000], Loss: 0.0384\n",
      "Epoch [2361/3000], Loss: 0.7067\n",
      "Epoch [2362/3000], Loss: 1.1727\n",
      "Epoch [2363/3000], Loss: 0.8872\n",
      "Epoch [2364/3000], Loss: 0.4948\n",
      "Epoch [2365/3000], Loss: 1.0595\n",
      "Epoch [2366/3000], Loss: 0.1566\n",
      "Epoch [2367/3000], Loss: 0.1672\n",
      "Epoch [2368/3000], Loss: 0.8959\n",
      "Epoch [2369/3000], Loss: 0.1690\n",
      "Epoch [2370/3000], Loss: 0.4591\n",
      "Epoch [2371/3000], Loss: 1.2970\n",
      "Epoch [2372/3000], Loss: 0.6740\n",
      "Epoch [2373/3000], Loss: 0.6936\n",
      "Epoch [2374/3000], Loss: 0.5509\n",
      "Epoch [2375/3000], Loss: 0.6110\n",
      "Epoch [2376/3000], Loss: 0.1241\n",
      "Epoch [2377/3000], Loss: 0.2821\n",
      "Epoch [2378/3000], Loss: 0.9599\n",
      "Epoch [2379/3000], Loss: 0.1692\n",
      "Epoch [2380/3000], Loss: 1.0539\n",
      "Epoch [2381/3000], Loss: 0.2971\n",
      "Epoch [2382/3000], Loss: 0.6801\n",
      "Epoch [2383/3000], Loss: 0.4496\n",
      "Epoch [2384/3000], Loss: 0.5805\n",
      "Epoch [2385/3000], Loss: 0.5899\n",
      "Epoch [2386/3000], Loss: 0.2713\n",
      "Epoch [2387/3000], Loss: 0.3316\n",
      "Epoch [2388/3000], Loss: 0.9433\n",
      "Epoch [2389/3000], Loss: 0.4722\n",
      "Epoch [2390/3000], Loss: 2.3784\n",
      "Epoch [2391/3000], Loss: 0.2350\n",
      "Epoch [2392/3000], Loss: 0.5066\n",
      "Epoch [2393/3000], Loss: 0.1612\n",
      "Epoch [2394/3000], Loss: 0.1233\n",
      "Epoch [2395/3000], Loss: 0.3598\n",
      "Epoch [2396/3000], Loss: 1.0169\n",
      "Epoch [2397/3000], Loss: 2.5088\n",
      "Epoch [2398/3000], Loss: 0.6400\n",
      "Epoch [2399/3000], Loss: 0.7072\n",
      "Epoch [2400/3000], Loss: 0.2975\n",
      "Epoch [2401/3000], Loss: 0.2040\n",
      "Epoch [2402/3000], Loss: 0.0734\n",
      "Epoch [2403/3000], Loss: 1.4744\n",
      "Epoch [2404/3000], Loss: 0.3583\n",
      "Epoch [2405/3000], Loss: 0.4685\n",
      "Epoch [2406/3000], Loss: 2.0013\n",
      "Epoch [2407/3000], Loss: 0.5144\n",
      "Epoch [2408/3000], Loss: 0.0119\n",
      "Epoch [2409/3000], Loss: 0.8387\n",
      "Epoch [2410/3000], Loss: 0.8453\n",
      "Epoch [2411/3000], Loss: 0.5572\n",
      "Epoch [2412/3000], Loss: 0.5419\n",
      "Epoch [2413/3000], Loss: 0.9858\n",
      "Epoch [2414/3000], Loss: 0.3890\n",
      "Epoch [2415/3000], Loss: 0.4017\n",
      "Epoch [2416/3000], Loss: 0.5146\n",
      "Epoch [2417/3000], Loss: 0.7730\n",
      "Epoch [2418/3000], Loss: 0.0579\n",
      "Epoch [2419/3000], Loss: 0.0421\n",
      "Epoch [2420/3000], Loss: 0.5423\n",
      "Epoch [2421/3000], Loss: 0.0051\n",
      "Epoch [2422/3000], Loss: 0.2212\n",
      "Epoch [2423/3000], Loss: 1.3923\n",
      "Epoch [2424/3000], Loss: 1.1708\n",
      "Epoch [2425/3000], Loss: 0.1018\n",
      "Epoch [2426/3000], Loss: 0.0759\n",
      "Epoch [2427/3000], Loss: 0.2598\n",
      "Epoch [2428/3000], Loss: 0.4069\n",
      "Epoch [2429/3000], Loss: 0.6816\n",
      "Epoch [2430/3000], Loss: 0.9599\n",
      "Epoch [2431/3000], Loss: 0.5637\n",
      "Epoch [2432/3000], Loss: 0.6156\n",
      "Epoch [2433/3000], Loss: 0.1917\n",
      "Epoch [2434/3000], Loss: 0.7925\n",
      "Epoch [2435/3000], Loss: 0.4399\n",
      "Epoch [2436/3000], Loss: 0.1109\n",
      "Epoch [2437/3000], Loss: 0.0412\n",
      "Epoch [2438/3000], Loss: 0.1970\n",
      "Epoch [2439/3000], Loss: 0.4321\n",
      "Epoch [2440/3000], Loss: 0.8560\n",
      "Epoch [2441/3000], Loss: 0.3452\n",
      "Epoch [2442/3000], Loss: 0.5387\n",
      "Epoch [2443/3000], Loss: 0.9840\n",
      "Epoch [2444/3000], Loss: 0.0659\n",
      "Epoch [2445/3000], Loss: 0.1313\n",
      "Epoch [2446/3000], Loss: 0.4249\n",
      "Epoch [2447/3000], Loss: 0.2282\n",
      "Epoch [2448/3000], Loss: 0.0985\n",
      "Epoch [2449/3000], Loss: 0.5998\n",
      "Epoch [2450/3000], Loss: 0.3417\n",
      "Epoch [2451/3000], Loss: 0.5932\n",
      "Epoch [2452/3000], Loss: 0.5230\n",
      "Epoch [2453/3000], Loss: 0.7481\n",
      "Epoch [2454/3000], Loss: 0.5332\n",
      "Epoch [2455/3000], Loss: 0.2081\n",
      "Epoch [2456/3000], Loss: 1.5918\n",
      "Epoch [2457/3000], Loss: 0.4688\n",
      "Epoch [2458/3000], Loss: 0.5109\n",
      "Epoch [2459/3000], Loss: 0.6422\n",
      "Epoch [2460/3000], Loss: 0.8816\n",
      "Epoch [2461/3000], Loss: 0.2001\n",
      "Epoch [2462/3000], Loss: 0.2697\n",
      "Epoch [2463/3000], Loss: 0.7749\n",
      "Epoch [2464/3000], Loss: 0.3945\n",
      "Epoch [2465/3000], Loss: 1.2443\n",
      "Epoch [2466/3000], Loss: 3.3549\n",
      "Epoch [2467/3000], Loss: 0.0856\n",
      "Epoch [2468/3000], Loss: 0.3737\n",
      "Epoch [2469/3000], Loss: 0.3491\n",
      "Epoch [2470/3000], Loss: 0.1009\n",
      "Epoch [2471/3000], Loss: 0.0797\n",
      "Epoch [2472/3000], Loss: 0.0674\n",
      "Epoch [2473/3000], Loss: 1.8356\n",
      "Epoch [2474/3000], Loss: 0.3203\n",
      "Epoch [2475/3000], Loss: 0.1183\n",
      "Epoch [2476/3000], Loss: 0.6168\n",
      "Epoch [2477/3000], Loss: 0.2243\n",
      "Epoch [2478/3000], Loss: 0.0278\n",
      "Epoch [2479/3000], Loss: 0.8312\n",
      "Epoch [2480/3000], Loss: 0.1339\n",
      "Epoch [2481/3000], Loss: 0.2383\n",
      "Epoch [2482/3000], Loss: 1.3462\n",
      "Epoch [2483/3000], Loss: 1.1274\n",
      "Epoch [2484/3000], Loss: 0.9353\n",
      "Epoch [2485/3000], Loss: 0.5502\n",
      "Epoch [2486/3000], Loss: 0.5447\n",
      "Epoch [2487/3000], Loss: 0.1043\n",
      "Epoch [2488/3000], Loss: 1.2192\n",
      "Epoch [2489/3000], Loss: 0.0923\n",
      "Epoch [2490/3000], Loss: 1.2051\n",
      "Epoch [2491/3000], Loss: 1.6803\n",
      "Epoch [2492/3000], Loss: 0.6482\n",
      "Epoch [2493/3000], Loss: 0.7897\n",
      "Epoch [2494/3000], Loss: 0.6801\n",
      "Epoch [2495/3000], Loss: 0.6300\n",
      "Epoch [2496/3000], Loss: 0.7107\n",
      "Epoch [2497/3000], Loss: 0.0784\n",
      "Epoch [2498/3000], Loss: 0.0522\n",
      "Epoch [2499/3000], Loss: 0.1016\n",
      "Epoch [2500/3000], Loss: 0.0932\n",
      "Epoch [2501/3000], Loss: 0.3831\n",
      "Epoch [2502/3000], Loss: 1.0804\n",
      "Epoch [2503/3000], Loss: 0.0345\n",
      "Epoch [2504/3000], Loss: 1.2399\n",
      "Epoch [2505/3000], Loss: 0.4313\n",
      "Epoch [2506/3000], Loss: 0.2753\n",
      "Epoch [2507/3000], Loss: 1.7221\n",
      "Epoch [2508/3000], Loss: 0.4825\n",
      "Epoch [2509/3000], Loss: 0.2521\n",
      "Epoch [2510/3000], Loss: 0.0159\n",
      "Epoch [2511/3000], Loss: 0.6862\n",
      "Epoch [2512/3000], Loss: 1.7293\n",
      "Epoch [2513/3000], Loss: 1.4862\n",
      "Epoch [2514/3000], Loss: 0.4559\n",
      "Epoch [2515/3000], Loss: 0.0178\n",
      "Epoch [2516/3000], Loss: 1.7346\n",
      "Epoch [2517/3000], Loss: 0.5066\n",
      "Epoch [2518/3000], Loss: 0.0824\n",
      "Epoch [2519/3000], Loss: 0.3276\n",
      "Epoch [2520/3000], Loss: 0.7282\n",
      "Epoch [2521/3000], Loss: 0.7139\n",
      "Epoch [2522/3000], Loss: 0.3056\n",
      "Epoch [2523/3000], Loss: 1.0246\n",
      "Epoch [2524/3000], Loss: 0.7517\n",
      "Epoch [2525/3000], Loss: 1.1013\n",
      "Epoch [2526/3000], Loss: 0.0640\n",
      "Epoch [2527/3000], Loss: 2.5965\n",
      "Epoch [2528/3000], Loss: 0.6597\n",
      "Epoch [2529/3000], Loss: 1.6195\n",
      "Epoch [2530/3000], Loss: 0.5048\n",
      "Epoch [2531/3000], Loss: 0.1702\n",
      "Epoch [2532/3000], Loss: 0.3825\n",
      "Epoch [2533/3000], Loss: 0.1834\n",
      "Epoch [2534/3000], Loss: 0.0261\n",
      "Epoch [2535/3000], Loss: 0.2234\n",
      "Epoch [2536/3000], Loss: 0.5134\n",
      "Epoch [2537/3000], Loss: 0.2541\n",
      "Epoch [2538/3000], Loss: 0.0616\n",
      "Epoch [2539/3000], Loss: 0.7019\n",
      "Epoch [2540/3000], Loss: 0.6189\n",
      "Epoch [2541/3000], Loss: 0.5355\n",
      "Epoch [2542/3000], Loss: 0.1725\n",
      "Epoch [2543/3000], Loss: 0.6030\n",
      "Epoch [2544/3000], Loss: 0.2320\n",
      "Epoch [2545/3000], Loss: 0.9185\n",
      "Epoch [2546/3000], Loss: 0.3606\n",
      "Epoch [2547/3000], Loss: 0.3726\n",
      "Epoch [2548/3000], Loss: 0.5560\n",
      "Epoch [2549/3000], Loss: 1.0981\n",
      "Epoch [2550/3000], Loss: 0.7892\n",
      "Epoch [2551/3000], Loss: 0.0216\n",
      "Epoch [2552/3000], Loss: 0.2436\n",
      "Epoch [2553/3000], Loss: 0.3348\n",
      "Epoch [2554/3000], Loss: 0.2382\n",
      "Epoch [2555/3000], Loss: 0.9783\n",
      "Epoch [2556/3000], Loss: 0.2614\n",
      "Epoch [2557/3000], Loss: 1.3170\n",
      "Epoch [2558/3000], Loss: 1.6546\n",
      "Epoch [2559/3000], Loss: 0.4147\n",
      "Epoch [2560/3000], Loss: 0.5559\n",
      "Epoch [2561/3000], Loss: 0.4045\n",
      "Epoch [2562/3000], Loss: 1.7099\n",
      "Epoch [2563/3000], Loss: 0.0360\n",
      "Epoch [2564/3000], Loss: 0.7422\n",
      "Epoch [2565/3000], Loss: 0.5412\n",
      "Epoch [2566/3000], Loss: 1.1566\n",
      "Epoch [2567/3000], Loss: 0.8367\n",
      "Epoch [2568/3000], Loss: 0.8179\n",
      "Epoch [2569/3000], Loss: 0.9370\n",
      "Epoch [2570/3000], Loss: 0.8570\n",
      "Epoch [2571/3000], Loss: 0.2091\n",
      "Epoch [2572/3000], Loss: 0.3305\n",
      "Epoch [2573/3000], Loss: 0.2775\n",
      "Epoch [2574/3000], Loss: 1.4409\n",
      "Epoch [2575/3000], Loss: 0.1267\n",
      "Epoch [2576/3000], Loss: 0.4977\n",
      "Epoch [2577/3000], Loss: 0.0073\n",
      "Epoch [2578/3000], Loss: 0.8412\n",
      "Epoch [2579/3000], Loss: 1.2019\n",
      "Epoch [2580/3000], Loss: 0.9284\n",
      "Epoch [2581/3000], Loss: 0.6294\n",
      "Epoch [2582/3000], Loss: 0.4080\n",
      "Epoch [2583/3000], Loss: 0.2030\n",
      "Epoch [2584/3000], Loss: 0.0329\n",
      "Epoch [2585/3000], Loss: 0.3506\n",
      "Epoch [2586/3000], Loss: 1.0105\n",
      "Epoch [2587/3000], Loss: 0.8503\n",
      "Epoch [2588/3000], Loss: 0.7063\n",
      "Epoch [2589/3000], Loss: 0.3955\n",
      "Epoch [2590/3000], Loss: 1.7340\n",
      "Epoch [2591/3000], Loss: 1.9500\n",
      "Epoch [2592/3000], Loss: 0.6314\n",
      "Epoch [2593/3000], Loss: 0.3745\n",
      "Epoch [2594/3000], Loss: 0.5611\n",
      "Epoch [2595/3000], Loss: 0.8202\n",
      "Epoch [2596/3000], Loss: 0.1017\n",
      "Epoch [2597/3000], Loss: 0.1052\n",
      "Epoch [2598/3000], Loss: 0.1704\n",
      "Epoch [2599/3000], Loss: 0.7507\n",
      "Epoch [2600/3000], Loss: 1.0694\n",
      "Epoch [2601/3000], Loss: 0.8340\n",
      "Epoch [2602/3000], Loss: 0.0060\n",
      "Epoch [2603/3000], Loss: 0.4399\n",
      "Epoch [2604/3000], Loss: 0.1406\n",
      "Epoch [2605/3000], Loss: 1.3121\n",
      "Epoch [2606/3000], Loss: 0.0063\n",
      "Epoch [2607/3000], Loss: 0.1250\n",
      "Epoch [2608/3000], Loss: 0.9576\n",
      "Epoch [2609/3000], Loss: 0.1418\n",
      "Epoch [2610/3000], Loss: 0.2133\n",
      "Epoch [2611/3000], Loss: 1.1434\n",
      "Epoch [2612/3000], Loss: 0.5532\n",
      "Epoch [2613/3000], Loss: 0.1320\n",
      "Epoch [2614/3000], Loss: 1.5345\n",
      "Epoch [2615/3000], Loss: 0.0948\n",
      "Epoch [2616/3000], Loss: 0.5591\n",
      "Epoch [2617/3000], Loss: 0.5787\n",
      "Epoch [2618/3000], Loss: 0.0403\n",
      "Epoch [2619/3000], Loss: 0.7594\n",
      "Epoch [2620/3000], Loss: 0.2711\n",
      "Epoch [2621/3000], Loss: 0.2554\n",
      "Epoch [2622/3000], Loss: 0.0897\n",
      "Epoch [2623/3000], Loss: 1.1425\n",
      "Epoch [2624/3000], Loss: 1.4232\n",
      "Epoch [2625/3000], Loss: 1.1032\n",
      "Epoch [2626/3000], Loss: 0.4294\n",
      "Epoch [2627/3000], Loss: 0.1837\n",
      "Epoch [2628/3000], Loss: 0.0971\n",
      "Epoch [2629/3000], Loss: 1.1849\n",
      "Epoch [2630/3000], Loss: 0.8126\n",
      "Epoch [2631/3000], Loss: 0.5621\n",
      "Epoch [2632/3000], Loss: 0.5394\n",
      "Epoch [2633/3000], Loss: 0.6749\n",
      "Epoch [2634/3000], Loss: 0.2025\n",
      "Epoch [2635/3000], Loss: 0.5073\n",
      "Epoch [2636/3000], Loss: 0.2165\n",
      "Epoch [2637/3000], Loss: 0.8091\n",
      "Epoch [2638/3000], Loss: 0.8730\n",
      "Epoch [2639/3000], Loss: 0.5530\n",
      "Epoch [2640/3000], Loss: 0.3239\n",
      "Epoch [2641/3000], Loss: 0.3107\n",
      "Epoch [2642/3000], Loss: 0.7523\n",
      "Epoch [2643/3000], Loss: 0.8949\n",
      "Epoch [2644/3000], Loss: 0.4466\n",
      "Epoch [2645/3000], Loss: 0.1088\n",
      "Epoch [2646/3000], Loss: 1.1263\n",
      "Epoch [2647/3000], Loss: 1.2815\n",
      "Epoch [2648/3000], Loss: 0.4407\n",
      "Epoch [2649/3000], Loss: 1.0187\n",
      "Epoch [2650/3000], Loss: 0.4995\n",
      "Epoch [2651/3000], Loss: 0.1451\n",
      "Epoch [2652/3000], Loss: 0.4972\n",
      "Epoch [2653/3000], Loss: 0.7894\n",
      "Epoch [2654/3000], Loss: 1.6593\n",
      "Epoch [2655/3000], Loss: 0.2579\n",
      "Epoch [2656/3000], Loss: 0.1153\n",
      "Epoch [2657/3000], Loss: 0.8422\n",
      "Epoch [2658/3000], Loss: 0.4025\n",
      "Epoch [2659/3000], Loss: 0.0121\n",
      "Epoch [2660/3000], Loss: 0.5052\n",
      "Epoch [2661/3000], Loss: 0.7452\n",
      "Epoch [2662/3000], Loss: 0.3294\n",
      "Epoch [2663/3000], Loss: 0.5601\n",
      "Epoch [2664/3000], Loss: 0.5115\n",
      "Epoch [2665/3000], Loss: 0.3046\n",
      "Epoch [2666/3000], Loss: 0.6554\n",
      "Epoch [2667/3000], Loss: 0.1177\n",
      "Epoch [2668/3000], Loss: 0.3183\n",
      "Epoch [2669/3000], Loss: 0.7645\n",
      "Epoch [2670/3000], Loss: 0.0376\n",
      "Epoch [2671/3000], Loss: 0.7553\n",
      "Epoch [2672/3000], Loss: 0.8095\n",
      "Epoch [2673/3000], Loss: 0.5436\n",
      "Epoch [2674/3000], Loss: 1.1011\n",
      "Epoch [2675/3000], Loss: 1.3790\n",
      "Epoch [2676/3000], Loss: 0.2139\n",
      "Epoch [2677/3000], Loss: 1.0588\n",
      "Epoch [2678/3000], Loss: 0.3145\n",
      "Epoch [2679/3000], Loss: 0.6162\n",
      "Epoch [2680/3000], Loss: 0.7395\n",
      "Epoch [2681/3000], Loss: 0.2904\n",
      "Epoch [2682/3000], Loss: 0.3300\n",
      "Epoch [2683/3000], Loss: 1.3940\n",
      "Epoch [2684/3000], Loss: 0.9534\n",
      "Epoch [2685/3000], Loss: 0.0464\n",
      "Epoch [2686/3000], Loss: 0.5809\n",
      "Epoch [2687/3000], Loss: 0.5134\n",
      "Epoch [2688/3000], Loss: 1.0054\n",
      "Epoch [2689/3000], Loss: 0.1087\n",
      "Epoch [2690/3000], Loss: 1.5383\n",
      "Epoch [2691/3000], Loss: 0.9836\n",
      "Epoch [2692/3000], Loss: 0.2276\n",
      "Epoch [2693/3000], Loss: 0.3189\n",
      "Epoch [2694/3000], Loss: 0.1846\n",
      "Epoch [2695/3000], Loss: 0.1757\n",
      "Epoch [2696/3000], Loss: 1.0852\n",
      "Epoch [2697/3000], Loss: 0.1385\n",
      "Epoch [2698/3000], Loss: 0.3068\n",
      "Epoch [2699/3000], Loss: 0.1922\n",
      "Epoch [2700/3000], Loss: 0.5873\n",
      "Epoch [2701/3000], Loss: 0.7005\n",
      "Epoch [2702/3000], Loss: 0.0343\n",
      "Epoch [2703/3000], Loss: 0.3356\n",
      "Epoch [2704/3000], Loss: 0.0173\n",
      "Epoch [2705/3000], Loss: 0.2968\n",
      "Epoch [2706/3000], Loss: 0.4850\n",
      "Epoch [2707/3000], Loss: 0.9035\n",
      "Epoch [2708/3000], Loss: 0.6990\n",
      "Epoch [2709/3000], Loss: 0.7807\n",
      "Epoch [2710/3000], Loss: 0.6779\n",
      "Epoch [2711/3000], Loss: 0.8937\n",
      "Epoch [2712/3000], Loss: 0.2142\n",
      "Epoch [2713/3000], Loss: 0.6740\n",
      "Epoch [2714/3000], Loss: 1.2354\n",
      "Epoch [2715/3000], Loss: 0.0076\n",
      "Epoch [2716/3000], Loss: 0.5428\n",
      "Epoch [2717/3000], Loss: 0.8563\n",
      "Epoch [2718/3000], Loss: 0.0258\n",
      "Epoch [2719/3000], Loss: 0.9585\n",
      "Epoch [2720/3000], Loss: 0.4572\n",
      "Epoch [2721/3000], Loss: 0.3093\n",
      "Epoch [2722/3000], Loss: 0.2049\n",
      "Epoch [2723/3000], Loss: 0.5218\n",
      "Epoch [2724/3000], Loss: 0.5438\n",
      "Epoch [2725/3000], Loss: 0.5835\n",
      "Epoch [2726/3000], Loss: 0.0205\n",
      "Epoch [2727/3000], Loss: 0.2439\n",
      "Epoch [2728/3000], Loss: 0.7506\n",
      "Epoch [2729/3000], Loss: 0.5494\n",
      "Epoch [2730/3000], Loss: 2.0605\n",
      "Epoch [2731/3000], Loss: 0.2359\n",
      "Epoch [2732/3000], Loss: 0.4190\n",
      "Epoch [2733/3000], Loss: 0.5254\n",
      "Epoch [2734/3000], Loss: 1.0522\n",
      "Epoch [2735/3000], Loss: 0.0327\n",
      "Epoch [2736/3000], Loss: 0.6302\n",
      "Epoch [2737/3000], Loss: 0.8066\n",
      "Epoch [2738/3000], Loss: 0.3042\n",
      "Epoch [2739/3000], Loss: 1.2652\n",
      "Epoch [2740/3000], Loss: 0.2317\n",
      "Epoch [2741/3000], Loss: 0.9353\n",
      "Epoch [2742/3000], Loss: 0.6013\n",
      "Epoch [2743/3000], Loss: 0.1193\n",
      "Epoch [2744/3000], Loss: 0.6846\n",
      "Epoch [2745/3000], Loss: 0.8329\n",
      "Epoch [2746/3000], Loss: 0.8328\n",
      "Epoch [2747/3000], Loss: 0.6954\n",
      "Epoch [2748/3000], Loss: 1.1809\n",
      "Epoch [2749/3000], Loss: 0.1534\n",
      "Epoch [2750/3000], Loss: 0.4579\n",
      "Epoch [2751/3000], Loss: 1.2461\n",
      "Epoch [2752/3000], Loss: 0.2984\n",
      "Epoch [2753/3000], Loss: 0.4033\n",
      "Epoch [2754/3000], Loss: 0.9261\n",
      "Epoch [2755/3000], Loss: 0.4229\n",
      "Epoch [2756/3000], Loss: 1.2579\n",
      "Epoch [2757/3000], Loss: 0.2151\n",
      "Epoch [2758/3000], Loss: 0.7296\n",
      "Epoch [2759/3000], Loss: 1.3304\n",
      "Epoch [2760/3000], Loss: 0.3680\n",
      "Epoch [2761/3000], Loss: 0.4240\n",
      "Epoch [2762/3000], Loss: 1.1887\n",
      "Epoch [2763/3000], Loss: 0.0756\n",
      "Epoch [2764/3000], Loss: 0.3642\n",
      "Epoch [2765/3000], Loss: 0.1754\n",
      "Epoch [2766/3000], Loss: 0.9377\n",
      "Epoch [2767/3000], Loss: 1.7033\n",
      "Epoch [2768/3000], Loss: 0.4957\n",
      "Epoch [2769/3000], Loss: 1.1394\n",
      "Epoch [2770/3000], Loss: 0.8817\n",
      "Epoch [2771/3000], Loss: 1.0874\n",
      "Epoch [2772/3000], Loss: 0.0059\n",
      "Epoch [2773/3000], Loss: 0.3537\n",
      "Epoch [2774/3000], Loss: 0.3791\n",
      "Epoch [2775/3000], Loss: 0.6020\n",
      "Epoch [2776/3000], Loss: 0.7156\n",
      "Epoch [2777/3000], Loss: 0.5505\n",
      "Epoch [2778/3000], Loss: 0.7319\n",
      "Epoch [2779/3000], Loss: 0.4399\n",
      "Epoch [2780/3000], Loss: 0.5781\n",
      "Epoch [2781/3000], Loss: 0.7993\n",
      "Epoch [2782/3000], Loss: 0.8256\n",
      "Epoch [2783/3000], Loss: 0.2761\n",
      "Epoch [2784/3000], Loss: 0.2356\n",
      "Epoch [2785/3000], Loss: 0.2353\n",
      "Epoch [2786/3000], Loss: 0.1124\n",
      "Epoch [2787/3000], Loss: 0.4264\n",
      "Epoch [2788/3000], Loss: 0.1977\n",
      "Epoch [2789/3000], Loss: 2.6591\n",
      "Epoch [2790/3000], Loss: 0.0368\n",
      "Epoch [2791/3000], Loss: 0.1572\n",
      "Epoch [2792/3000], Loss: 0.1022\n",
      "Epoch [2793/3000], Loss: 1.1512\n",
      "Epoch [2794/3000], Loss: 0.4524\n",
      "Epoch [2795/3000], Loss: 0.0384\n",
      "Epoch [2796/3000], Loss: 0.7870\n",
      "Epoch [2797/3000], Loss: 1.2406\n",
      "Epoch [2798/3000], Loss: 0.5085\n",
      "Epoch [2799/3000], Loss: 1.5117\n",
      "Epoch [2800/3000], Loss: 2.0217\n",
      "Epoch [2801/3000], Loss: 0.8130\n",
      "Epoch [2802/3000], Loss: 0.1381\n",
      "Epoch [2803/3000], Loss: 0.5416\n",
      "Epoch [2804/3000], Loss: 0.8950\n",
      "Epoch [2805/3000], Loss: 0.1133\n",
      "Epoch [2806/3000], Loss: 0.1974\n",
      "Epoch [2807/3000], Loss: 0.6603\n",
      "Epoch [2808/3000], Loss: 0.2846\n",
      "Epoch [2809/3000], Loss: 0.6189\n",
      "Epoch [2810/3000], Loss: 0.4054\n",
      "Epoch [2811/3000], Loss: 0.2577\n",
      "Epoch [2812/3000], Loss: 1.3995\n",
      "Epoch [2813/3000], Loss: 0.1814\n",
      "Epoch [2814/3000], Loss: 2.7697\n",
      "Epoch [2815/3000], Loss: 0.0274\n",
      "Epoch [2816/3000], Loss: 0.9604\n",
      "Epoch [2817/3000], Loss: 1.8051\n",
      "Epoch [2818/3000], Loss: 0.5528\n",
      "Epoch [2819/3000], Loss: 0.1593\n",
      "Epoch [2820/3000], Loss: 0.3664\n",
      "Epoch [2821/3000], Loss: 1.4305\n",
      "Epoch [2822/3000], Loss: 0.3258\n",
      "Epoch [2823/3000], Loss: 1.2059\n",
      "Epoch [2824/3000], Loss: 0.6747\n",
      "Epoch [2825/3000], Loss: 0.6386\n",
      "Epoch [2826/3000], Loss: 0.2823\n",
      "Epoch [2827/3000], Loss: 1.1977\n",
      "Epoch [2828/3000], Loss: 0.0968\n",
      "Epoch [2829/3000], Loss: 1.3381\n",
      "Epoch [2830/3000], Loss: 1.2796\n",
      "Epoch [2831/3000], Loss: 0.8089\n",
      "Epoch [2832/3000], Loss: 0.7058\n",
      "Epoch [2833/3000], Loss: 0.3786\n",
      "Epoch [2834/3000], Loss: 0.9491\n",
      "Epoch [2835/3000], Loss: 0.8337\n",
      "Epoch [2836/3000], Loss: 0.5942\n",
      "Epoch [2837/3000], Loss: 2.1528\n",
      "Epoch [2838/3000], Loss: 1.0231\n",
      "Epoch [2839/3000], Loss: 0.5936\n",
      "Epoch [2840/3000], Loss: 1.0847\n",
      "Epoch [2841/3000], Loss: 0.6463\n",
      "Epoch [2842/3000], Loss: 0.1387\n",
      "Epoch [2843/3000], Loss: 0.6262\n",
      "Epoch [2844/3000], Loss: 1.8967\n",
      "Epoch [2845/3000], Loss: 0.3550\n",
      "Epoch [2846/3000], Loss: 2.9652\n",
      "Epoch [2847/3000], Loss: 0.6250\n",
      "Epoch [2848/3000], Loss: 0.2926\n",
      "Epoch [2849/3000], Loss: 1.2647\n",
      "Epoch [2850/3000], Loss: 1.0139\n",
      "Epoch [2851/3000], Loss: 0.7277\n",
      "Epoch [2852/3000], Loss: 0.3303\n",
      "Epoch [2853/3000], Loss: 0.8669\n",
      "Epoch [2854/3000], Loss: 0.7245\n",
      "Epoch [2855/3000], Loss: 0.6422\n",
      "Epoch [2856/3000], Loss: 1.3808\n",
      "Epoch [2857/3000], Loss: 0.0357\n",
      "Epoch [2858/3000], Loss: 0.2769\n",
      "Epoch [2859/3000], Loss: 0.2312\n",
      "Epoch [2860/3000], Loss: 0.4456\n",
      "Epoch [2861/3000], Loss: 0.5998\n",
      "Epoch [2862/3000], Loss: 1.7268\n",
      "Epoch [2863/3000], Loss: 0.7307\n",
      "Epoch [2864/3000], Loss: 2.1711\n",
      "Epoch [2865/3000], Loss: 0.2851\n",
      "Epoch [2866/3000], Loss: 0.2414\n",
      "Epoch [2867/3000], Loss: 0.7583\n",
      "Epoch [2868/3000], Loss: 1.2718\n",
      "Epoch [2869/3000], Loss: 0.8687\n",
      "Epoch [2870/3000], Loss: 0.4088\n",
      "Epoch [2871/3000], Loss: 1.8093\n",
      "Epoch [2872/3000], Loss: 1.1474\n",
      "Epoch [2873/3000], Loss: 1.0315\n",
      "Epoch [2874/3000], Loss: 0.4584\n",
      "Epoch [2875/3000], Loss: 0.2964\n",
      "Epoch [2876/3000], Loss: 1.0210\n",
      "Epoch [2877/3000], Loss: 0.1927\n",
      "Epoch [2878/3000], Loss: 0.1560\n",
      "Epoch [2879/3000], Loss: 1.1253\n",
      "Epoch [2880/3000], Loss: 0.4739\n",
      "Epoch [2881/3000], Loss: 0.0674\n",
      "Epoch [2882/3000], Loss: 0.3422\n",
      "Epoch [2883/3000], Loss: 1.5353\n",
      "Epoch [2884/3000], Loss: 0.1687\n",
      "Epoch [2885/3000], Loss: 0.5649\n",
      "Epoch [2886/3000], Loss: 1.0342\n",
      "Epoch [2887/3000], Loss: 0.4284\n",
      "Epoch [2888/3000], Loss: 1.3654\n",
      "Epoch [2889/3000], Loss: 0.1958\n",
      "Epoch [2890/3000], Loss: 1.7422\n",
      "Epoch [2891/3000], Loss: 0.5247\n",
      "Epoch [2892/3000], Loss: 0.3042\n",
      "Epoch [2893/3000], Loss: 0.3522\n",
      "Epoch [2894/3000], Loss: 0.8499\n",
      "Epoch [2895/3000], Loss: 0.7914\n",
      "Epoch [2896/3000], Loss: 0.5233\n",
      "Epoch [2897/3000], Loss: 0.0173\n",
      "Epoch [2898/3000], Loss: 0.3125\n",
      "Epoch [2899/3000], Loss: 0.1937\n",
      "Epoch [2900/3000], Loss: 0.2763\n",
      "Epoch [2901/3000], Loss: 1.0282\n",
      "Epoch [2902/3000], Loss: 0.2638\n",
      "Epoch [2903/3000], Loss: 0.5997\n",
      "Epoch [2904/3000], Loss: 0.0423\n",
      "Epoch [2905/3000], Loss: 1.1379\n",
      "Epoch [2906/3000], Loss: 0.1295\n",
      "Epoch [2907/3000], Loss: 0.1377\n",
      "Epoch [2908/3000], Loss: 0.0199\n",
      "Epoch [2909/3000], Loss: 1.1219\n",
      "Epoch [2910/3000], Loss: 0.4567\n",
      "Epoch [2911/3000], Loss: 1.2479\n",
      "Epoch [2912/3000], Loss: 0.3743\n",
      "Epoch [2913/3000], Loss: 0.0508\n",
      "Epoch [2914/3000], Loss: 0.1974\n",
      "Epoch [2915/3000], Loss: 0.8714\n",
      "Epoch [2916/3000], Loss: 0.9847\n",
      "Epoch [2917/3000], Loss: 0.3918\n",
      "Epoch [2918/3000], Loss: 0.0218\n",
      "Epoch [2919/3000], Loss: 1.4386\n",
      "Epoch [2920/3000], Loss: 0.1183\n",
      "Epoch [2921/3000], Loss: 0.9397\n",
      "Epoch [2922/3000], Loss: 0.0413\n",
      "Epoch [2923/3000], Loss: 2.6261\n",
      "Epoch [2924/3000], Loss: 0.8299\n",
      "Epoch [2925/3000], Loss: 0.3565\n",
      "Epoch [2926/3000], Loss: 0.0077\n",
      "Epoch [2927/3000], Loss: 0.0474\n",
      "Epoch [2928/3000], Loss: 0.1234\n",
      "Epoch [2929/3000], Loss: 0.0410\n",
      "Epoch [2930/3000], Loss: 0.7351\n",
      "Epoch [2931/3000], Loss: 0.3744\n",
      "Epoch [2932/3000], Loss: 1.6762\n",
      "Epoch [2933/3000], Loss: 1.1111\n",
      "Epoch [2934/3000], Loss: 0.4415\n",
      "Epoch [2935/3000], Loss: 0.6552\n",
      "Epoch [2936/3000], Loss: 0.0950\n",
      "Epoch [2937/3000], Loss: 0.7827\n",
      "Epoch [2938/3000], Loss: 0.1795\n",
      "Epoch [2939/3000], Loss: 0.7289\n",
      "Epoch [2940/3000], Loss: 0.5324\n",
      "Epoch [2941/3000], Loss: 0.3174\n",
      "Epoch [2942/3000], Loss: 1.2897\n",
      "Epoch [2943/3000], Loss: 0.7979\n",
      "Epoch [2944/3000], Loss: 0.2590\n",
      "Epoch [2945/3000], Loss: 1.0384\n",
      "Epoch [2946/3000], Loss: 1.4973\n",
      "Epoch [2947/3000], Loss: 0.9960\n",
      "Epoch [2948/3000], Loss: 0.3336\n",
      "Epoch [2949/3000], Loss: 0.2088\n",
      "Epoch [2950/3000], Loss: 1.3244\n",
      "Epoch [2951/3000], Loss: 1.4485\n",
      "Epoch [2952/3000], Loss: 0.5624\n",
      "Epoch [2953/3000], Loss: 0.2554\n",
      "Epoch [2954/3000], Loss: 0.3760\n",
      "Epoch [2955/3000], Loss: 1.9341\n",
      "Epoch [2956/3000], Loss: 0.2766\n",
      "Epoch [2957/3000], Loss: 0.7095\n",
      "Epoch [2958/3000], Loss: 1.3877\n",
      "Epoch [2959/3000], Loss: 0.0777\n",
      "Epoch [2960/3000], Loss: 1.0162\n",
      "Epoch [2961/3000], Loss: 0.3070\n",
      "Epoch [2962/3000], Loss: 3.1038\n",
      "Epoch [2963/3000], Loss: 0.3201\n",
      "Epoch [2964/3000], Loss: 0.3099\n",
      "Epoch [2965/3000], Loss: 0.5158\n",
      "Epoch [2966/3000], Loss: 0.4839\n",
      "Epoch [2967/3000], Loss: 0.0301\n",
      "Epoch [2968/3000], Loss: 0.9146\n",
      "Epoch [2969/3000], Loss: 1.2700\n",
      "Epoch [2970/3000], Loss: 0.6255\n",
      "Epoch [2971/3000], Loss: 0.7202\n",
      "Epoch [2972/3000], Loss: 0.3804\n",
      "Epoch [2973/3000], Loss: 0.0724\n",
      "Epoch [2974/3000], Loss: 1.1820\n",
      "Epoch [2975/3000], Loss: 0.1221\n",
      "Epoch [2976/3000], Loss: 0.4951\n",
      "Epoch [2977/3000], Loss: 0.0206\n",
      "Epoch [2978/3000], Loss: 0.6895\n",
      "Epoch [2979/3000], Loss: 0.5336\n",
      "Epoch [2980/3000], Loss: 0.4614\n",
      "Epoch [2981/3000], Loss: 1.3453\n",
      "Epoch [2982/3000], Loss: 0.4004\n",
      "Epoch [2983/3000], Loss: 1.1483\n",
      "Epoch [2984/3000], Loss: 0.0924\n",
      "Epoch [2985/3000], Loss: 0.6095\n",
      "Epoch [2986/3000], Loss: 0.9262\n",
      "Epoch [2987/3000], Loss: 0.1150\n",
      "Epoch [2988/3000], Loss: 0.4296\n",
      "Epoch [2989/3000], Loss: 0.5542\n",
      "Epoch [2990/3000], Loss: 0.5669\n",
      "Epoch [2991/3000], Loss: 0.2300\n",
      "Epoch [2992/3000], Loss: 0.5328\n",
      "Epoch [2993/3000], Loss: 0.5705\n",
      "Epoch [2994/3000], Loss: 0.2818\n",
      "Epoch [2995/3000], Loss: 1.0563\n",
      "Epoch [2996/3000], Loss: 0.4428\n",
      "Epoch [2997/3000], Loss: 0.6867\n",
      "Epoch [2998/3000], Loss: 0.5149\n",
      "Epoch [2999/3000], Loss: 0.2784\n",
      "Epoch [3000/3000], Loss: 0.2166\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3000  # Adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print training loss\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.ones((16))*2\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.from_numpy(x1).float()\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2947, -0.3281,  0.0557], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_name = f'NN_{input_dim}_{hidden_dim}_{output_dim}.pth'\n",
    "\n",
    "torch.save(model.state_dict(), NN_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
